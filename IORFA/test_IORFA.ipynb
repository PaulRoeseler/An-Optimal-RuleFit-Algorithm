{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d4e0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iorfa_l1_flow_indicators_fast.py\n",
    "from __future__ import annotations\n",
    "\n",
    "from collections import namedtuple\n",
    "from dataclasses import dataclass\n",
    "from typing import Literal\n",
    "\n",
    "import numpy as np\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "class OptimalRegressionTreeFlow:\n",
    "    \"\"\"\n",
    "    Optimal regression tree with integrated linear term, L1 loss.\n",
    "\n",
    "    Prediction:\n",
    "        f(x) = x @ beta + gamma_leaf(x)\n",
    "\n",
    "    New (optional) speed/accuracy features while keeping interpretability:\n",
    "      - routing_formulation:\n",
    "            \"indicator\" (your original indicator routing), or\n",
    "            \"bigm\"      (no routing indicators, no rdir binaries; typically faster)\n",
    "      - leaf_value_formulation:\n",
    "            \"indicator\" (your original leaf-value indicators), or\n",
    "            \"bigm\"      (replaces with tight big-M constraints; typically faster)\n",
    "      - max_thresholds:\n",
    "            if set, restrict b[t] to a small set of candidate thresholds per feature\n",
    "            (interpretability preserved; often faster and more stable)\n",
    "      - lambda_beta_l1 / lambda_gamma_l1:\n",
    "            RuleFit-like sparsity on linear term and/or leaf offsets\n",
    "      - polish:\n",
    "            after MIP, fix integer vars and re-optimize continuous vars (LP), fast improvement\n",
    "\n",
    "    Objective:\n",
    "        min (1/n) * sum_i | y_i - x_i^T beta - s_i |  + alpha * sum_{branch t} d_t\n",
    "            + lambda_beta_l1 * sum_j |beta_j| + lambda_gamma_l1 * sum_leaf |gamma_leaf|\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_depth: int = 3,\n",
    "        min_samples_split: int | None = None,   # alias\n",
    "        min_samples_leaf: int | None = None,    # preferred\n",
    "        alpha: float = 0.0,\n",
    "\n",
    "        # speed/accuracy knobs\n",
    "        routing_formulation: Literal[\"indicator\", \"bigm\"] = \"bigm\",\n",
    "        leaf_value_formulation: Literal[\"indicator\", \"bigm\"] = \"bigm\",\n",
    "        max_thresholds: int | None = None,  # e.g. 32; None keeps continuous b\n",
    "        threshold_strategy: Literal[\"quantile\", \"uniform\"] = \"quantile\",\n",
    "        lambda_beta_l1: float = 0.0,\n",
    "        lambda_gamma_l1: float = 0.0,\n",
    "        polish: bool = True,\n",
    "        polish_timelimit: float = 10.0,\n",
    "\n",
    "        warmstart: bool = True,\n",
    "        timelimit: float = 600.0,\n",
    "        mipgap: float | None = None,\n",
    "        output: bool = True,\n",
    "        gamma_bounds: tuple[float, float] = (-10000.0, 10000.0),\n",
    "        beta_bounds: tuple[float, float] | None = None,\n",
    "        eps_tie: float = 1e-9,\n",
    "        threads: int = 0,\n",
    "        seed: int = 0,\n",
    "        heuristics: float | None = None,\n",
    "    ):\n",
    "        self.max_depth = int(max_depth)\n",
    "\n",
    "        if min_samples_leaf is not None:\n",
    "            self.min_samples_leaf = int(min_samples_leaf)\n",
    "        elif min_samples_split is not None:\n",
    "            self.min_samples_leaf = int(min_samples_split)\n",
    "        else:\n",
    "            self.min_samples_leaf = 2\n",
    "\n",
    "        self.alpha = float(alpha)\n",
    "        self.routing_formulation = routing_formulation\n",
    "        self.leaf_value_formulation = leaf_value_formulation\n",
    "        self.max_thresholds = None if max_thresholds is None else int(max_thresholds)\n",
    "        self.threshold_strategy = threshold_strategy\n",
    "        self.lambda_beta_l1 = float(lambda_beta_l1)\n",
    "        self.lambda_gamma_l1 = float(lambda_gamma_l1)\n",
    "        self.polish = bool(polish)\n",
    "        self.polish_timelimit = float(polish_timelimit)\n",
    "\n",
    "        self.warmstart = bool(warmstart)\n",
    "        self.timelimit = float(timelimit)\n",
    "        self.mipgap = mipgap\n",
    "        self.output = bool(output)\n",
    "        self.gamma_bounds = (float(gamma_bounds[0]), float(gamma_bounds[1]))\n",
    "        self.beta_bounds = beta_bounds\n",
    "        self.eps_tie = float(eps_tie)\n",
    "        self.threads = int(threads)\n",
    "        self.seed = int(seed)\n",
    "        self.heuristics = heuristics\n",
    "\n",
    "        self.trained = False\n",
    "        self.optgap = None\n",
    "\n",
    "        self.feature_names_ = None\n",
    "        self.feature_mins_ = None\n",
    "        self.feature_maxs_ = None\n",
    "        self._threshold_candidates_ = None  # if max_thresholds is used\n",
    "\n",
    "        # learned params\n",
    "        self._beta = None\n",
    "        self._gamma = None\n",
    "        self._a = None\n",
    "        self._b = None\n",
    "        self._d = None\n",
    "\n",
    "        # node indices: 1..(2^(D+1)-1)\n",
    "        self.n_index = [i + 1 for i in range(2 ** (self.max_depth + 1) - 1)]\n",
    "        self.b_index = self.n_index[: -2**self.max_depth]         # branch nodes\n",
    "        self.l_index = self.n_index[-2**self.max_depth :]         # leaves\n",
    "\n",
    "        self.n = None\n",
    "        self.p = None\n",
    "        self.m = None\n",
    "\n",
    "    # ---------------------------\n",
    "    # Public API\n",
    "    # ---------------------------\n",
    "    def fit(self, x, y):\n",
    "        if hasattr(x, \"columns\"):\n",
    "            self.feature_names_ = list(x.columns)\n",
    "\n",
    "        x = np.asarray(x, dtype=float)\n",
    "        y = np.asarray(y, dtype=float).ravel()\n",
    "\n",
    "        if x.ndim != 2:\n",
    "            raise ValueError(\"x must be 2D (n_samples, n_features)\")\n",
    "        if y.ndim != 1:\n",
    "            raise ValueError(\"y must be 1D (n_samples,)\")\n",
    "        if x.shape[0] != y.shape[0]:\n",
    "            raise ValueError(\"x and y must have same number of rows\")\n",
    "\n",
    "        self.n, self.p = x.shape\n",
    "        self.feature_mins_ = np.min(x, axis=0)\n",
    "        self.feature_maxs_ = np.max(x, axis=0)\n",
    "\n",
    "        if self.output:\n",
    "            print(f\"Training data include {self.n} instances, {self.p} features.\")\n",
    "\n",
    "        (\n",
    "            m,\n",
    "            a, b, d,\n",
    "            q,\n",
    "            l, N,\n",
    "            beta, gamma,\n",
    "            s,\n",
    "            r, u,\n",
    "            zsplit,  # optional split-choice vars if thresholds discretized\n",
    "        ) = self._buildMILP(x, y)\n",
    "\n",
    "        m.update()\n",
    "\n",
    "        if self.warmstart:\n",
    "            self._setStart(\n",
    "                x, y,\n",
    "                a, b, d,\n",
    "                q,\n",
    "                l, N,\n",
    "                beta, gamma,\n",
    "                s,\n",
    "                r, u,\n",
    "                zsplit,\n",
    "            )\n",
    "\n",
    "        m.optimize()\n",
    "\n",
    "        # Optional fast \"polish\": fix binaries and re-optimize continuous vars as LP\n",
    "        if self.polish and m.SolCount > 0:\n",
    "            self._polish_solution(\n",
    "                m,\n",
    "                a=a, d=d, q=q, l=l, zsplit=zsplit,\n",
    "            )\n",
    "\n",
    "        self.m = m\n",
    "        self.optgap = getattr(m, \"MIPGap\", None)\n",
    "\n",
    "        self._a = {(j, t): a[j, t].X for j in range(self.p) for t in self.b_index}\n",
    "        self._b = {t: b[t].X for t in self.b_index}\n",
    "        self._d = {t: d[t].X for t in self.b_index}\n",
    "        self._beta = np.array([beta[j].X for j in range(self.p)], dtype=float)\n",
    "        self._gamma = {t: gamma[t].X for t in self.l_index}\n",
    "\n",
    "        self.trained = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        if not self.trained:\n",
    "            raise AssertionError(\"This instance is not fitted yet.\")\n",
    "\n",
    "        x = np.asarray(x, dtype=float)\n",
    "        if x.ndim == 1:\n",
    "            x = x.reshape(1, -1)\n",
    "        if x.shape[1] != self.p:\n",
    "            raise ValueError(f\"Expected {self.p} features, got {x.shape[1]}\")\n",
    "\n",
    "        y_pred = np.zeros(x.shape[0], dtype=float)\n",
    "\n",
    "        for i, xi in enumerate(x):\n",
    "            t = 1\n",
    "            while t not in self.l_index:\n",
    "                if self._d.get(t, 0.0) < 0.5:\n",
    "                    t = 2 * t + 1\n",
    "                    continue\n",
    "\n",
    "                split_val = 0.0\n",
    "                for j in range(self.p):\n",
    "                    split_val += self._a.get((j, t), 0.0) * xi[j]\n",
    "\n",
    "                if split_val + self.eps_tie >= self._b[t]:\n",
    "                    t = 2 * t + 1\n",
    "                else:\n",
    "                    t = 2 * t\n",
    "            y_pred[i] = float(np.dot(xi, self._beta) + self._gamma[t])\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    # ---------------------------\n",
    "    # Core MIP\n",
    "    # ---------------------------\n",
    "    def _buildMILP(self, x: np.ndarray, y: np.ndarray):\n",
    "        m = gp.Model(\"iorfa_l1_flow_fast\")\n",
    "\n",
    "        m.Params.OutputFlag = 1 if self.output else 0\n",
    "        m.Params.LogToConsole = 1 if self.output else 0\n",
    "        m.Params.TimeLimit = self.timelimit\n",
    "        m.Params.Threads = self.threads\n",
    "        m.ModelSense = GRB.MINIMIZE\n",
    "        if self.heuristics is not None:\n",
    "            m.Params.Heuristics = float(self.heuristics)\n",
    "        m.Params.Seed = self.seed\n",
    "        if self.mipgap is not None:\n",
    "            m.Params.MIPGap = float(self.mipgap)\n",
    "\n",
    "        # -----------------------\n",
    "        # Variables\n",
    "        # -----------------------\n",
    "        a = m.addVars(self.p, self.b_index, vtype=GRB.BINARY, name=\"a\")\n",
    "        b = m.addVars(self.b_index, vtype=GRB.CONTINUOUS, name=\"b\")\n",
    "        d = m.addVars(self.b_index, vtype=GRB.BINARY, name=\"d\")\n",
    "\n",
    "        # flow: q[i,t] is 1 if sample i reaches node t\n",
    "        q = m.addVars(self.n, self.n_index, vtype=GRB.BINARY, name=\"q\")\n",
    "\n",
    "        # leaf activation + counts\n",
    "        l = m.addVars(self.l_index, vtype=GRB.BINARY, name=\"l\")\n",
    "        N = m.addVars(self.l_index, lb=0.0, vtype=GRB.CONTINUOUS, name=\"N\")\n",
    "\n",
    "        # linear term\n",
    "        if self.beta_bounds is None:\n",
    "            beta = m.addVars(self.p, vtype=GRB.CONTINUOUS, name=\"beta\")\n",
    "        else:\n",
    "            lb, ub = self.beta_bounds\n",
    "            beta = m.addVars(self.p, lb=float(lb), ub=float(ub), vtype=GRB.CONTINUOUS, name=\"beta\")\n",
    "\n",
    "        # leaf offsets\n",
    "        Lower, Upper = self.gamma_bounds\n",
    "        gamma = m.addVars(self.l_index, lb=Lower, ub=Upper, vtype=GRB.CONTINUOUS, name=\"gamma\")\n",
    "\n",
    "        # s_i = selected gamma\n",
    "        s = m.addVars(self.n, vtype=GRB.CONTINUOUS, name=\"s\")\n",
    "\n",
    "        # residual + abs\n",
    "        r = m.addVars(self.n, lb=-GRB.INFINITY, vtype=GRB.CONTINUOUS, name=\"r\")\n",
    "        u = m.addVars(self.n, lb=0.0, vtype=GRB.CONTINUOUS, name=\"abs_r\")\n",
    "\n",
    "        # Optional: discrete split choices (feature, threshold)\n",
    "        zsplit = None\n",
    "        if self.max_thresholds is not None:\n",
    "            self._threshold_candidates_ = self._compute_threshold_candidates(x)\n",
    "            keys = []\n",
    "            for t in self.b_index:\n",
    "                for j in range(self.p):\n",
    "                    Kj = len(self._threshold_candidates_[j])\n",
    "                    for k in range(Kj):\n",
    "                        keys.append((j, k, t))\n",
    "            zsplit = m.addVars(keys, vtype=GRB.BINARY, name=\"zsplit\")\n",
    "\n",
    "        # -----------------------\n",
    "        # Objective\n",
    "        # -----------------------\n",
    "        complexity = gp.quicksum(d[t] for t in self.b_index)\n",
    "\n",
    "        obj = (1.0 / self.n) * u.sum() + self.alpha * complexity\n",
    "\n",
    "        # RuleFit-style sparsity penalties (optional)\n",
    "        if self.lambda_beta_l1 > 0.0:\n",
    "            beta_abs = m.addVars(self.p, lb=0.0, vtype=GRB.CONTINUOUS, name=\"beta_abs\")\n",
    "            m.addConstrs((beta_abs[j] >= beta[j] for j in range(self.p)), name=\"beta_abs_pos\")\n",
    "            m.addConstrs((beta_abs[j] >= -beta[j] for j in range(self.p)), name=\"beta_abs_neg\")\n",
    "            obj += self.lambda_beta_l1 * gp.quicksum(beta_abs[j] for j in range(self.p))\n",
    "\n",
    "        if self.lambda_gamma_l1 > 0.0:\n",
    "            gamma_abs = m.addVars(self.l_index, lb=0.0, vtype=GRB.CONTINUOUS, name=\"gamma_abs\")\n",
    "            m.addConstrs((gamma_abs[lf] >= gamma[lf] for lf in self.l_index), name=\"gamma_abs_pos\")\n",
    "            m.addConstrs((gamma_abs[lf] >= -gamma[lf] for lf in self.l_index), name=\"gamma_abs_neg\")\n",
    "            obj += self.lambda_gamma_l1 * gp.quicksum(gamma_abs[lf] for lf in self.l_index)\n",
    "\n",
    "        m.setObjective(obj)\n",
    "\n",
    "        # -----------------------\n",
    "        # Structure / flow\n",
    "        # -----------------------\n",
    "        m.addConstrs((q[i, 1] == 1 for i in range(self.n)), name=\"root_flow\")\n",
    "\n",
    "        for t in self.b_index:\n",
    "            lt = 2 * t\n",
    "            rt = 2 * t + 1\n",
    "\n",
    "            # child flows sum to parent\n",
    "            m.addConstrs((q[i, lt] + q[i, rt] == q[i, t] for i in range(self.n)), name=f\"flow[{t}]\")\n",
    "\n",
    "            # if inactive, force left=0 and right=parent (symmetry break)\n",
    "            m.addConstrs((q[i, lt] <= d[t] for i in range(self.n)), name=f\"no_left_if_inactive[{t}]\")\n",
    "            m.addConstrs((q[i, rt] >= q[i, t] - d[t] for i in range(self.n)), name=f\"must_go_right_if_inactive[{t}]\")\n",
    "\n",
    "        # one leaf per sample\n",
    "        m.addConstrs((gp.quicksum(q[i, lf] for lf in self.l_index) == 1 for i in range(self.n)), name=\"one_leaf\")\n",
    "\n",
    "        # leaf counts / activation\n",
    "        m.addConstrs((N[lf] == gp.quicksum(q[i, lf] for i in range(self.n)) for lf in self.l_index), name=\"leaf_counts\")\n",
    "        m.addConstrs((q[i, lf] <= l[lf] for i in range(self.n) for lf in self.l_index), name=\"leaf_active_if_used\")\n",
    "        m.addConstrs((N[lf] >= self.min_samples_leaf * l[lf] for lf in self.l_index), name=\"min_leaf_size\")\n",
    "\n",
    "        # split selection + hierarchy\n",
    "        m.addConstrs((d[t] <= d[t // 2] for t in self.b_index if t != 1), name=\"parent_active\")\n",
    "\n",
    "        if zsplit is None:\n",
    "            # original: pick exactly one feature if split is active\n",
    "            m.addConstrs((gp.quicksum(a[j, t] for j in range(self.p)) == d[t] for t in self.b_index), name=\"one_feat_if_split\")\n",
    "\n",
    "            # b bounds: if inactive, a=0 => b forced to 0 by these bounds\n",
    "            feature_min = self.feature_mins_\n",
    "            feature_max = self.feature_maxs_\n",
    "            m.addConstrs(\n",
    "                (b[t] <= gp.quicksum(feature_max[j] * a[j, t] for j in range(self.p)) for t in self.b_index),\n",
    "                name=\"b_ub\",\n",
    "            )\n",
    "            m.addConstrs(\n",
    "                (b[t] >= gp.quicksum(feature_min[j] * a[j, t] for j in range(self.p)) for t in self.b_index),\n",
    "                name=\"b_lb\",\n",
    "            )\n",
    "        else:\n",
    "            # Discrete (feature, threshold) choice:\n",
    "            # sum_{j,k} zsplit[j,k,t] == d[t]\n",
    "            for t in self.b_index:\n",
    "                m.addConstr(\n",
    "                    gp.quicksum(\n",
    "                        zsplit[j, k, t]\n",
    "                        for j in range(self.p)\n",
    "                        for k in range(len(self._threshold_candidates_[j]))\n",
    "                    ) == d[t],\n",
    "                    name=f\"one_split_choice[{t}]\",\n",
    "                )\n",
    "\n",
    "            # link a[j,t] = sum_k zsplit[j,k,t]\n",
    "            m.addConstrs(\n",
    "                (\n",
    "                    a[j, t] == gp.quicksum(zsplit[j, k, t] for k in range(len(self._threshold_candidates_[j])))\n",
    "                    for j in range(self.p) for t in self.b_index\n",
    "                ),\n",
    "                name=\"a_from_zsplit\",\n",
    "            )\n",
    "\n",
    "            # set b[t] to chosen threshold (or 0 if inactive)\n",
    "            for t in self.b_index:\n",
    "                m.addConstr(\n",
    "                    b[t]\n",
    "                    == gp.quicksum(\n",
    "                        float(self._threshold_candidates_[j][k]) * zsplit[j, k, t]\n",
    "                        for j in range(self.p)\n",
    "                        for k in range(len(self._threshold_candidates_[j]))\n",
    "                    ),\n",
    "                    name=f\"b_from_zsplit[{t}]\",\n",
    "                )\n",
    "\n",
    "        # -----------------------\n",
    "        # Residual / abs\n",
    "        # -----------------------\n",
    "        for i in range(self.n):\n",
    "            m.addConstr(\n",
    "                r[i] == y[i] - gp.quicksum(x[i, j] * beta[j] for j in range(self.p)) - s[i],\n",
    "                name=f\"res_def[{i}]\",\n",
    "            )\n",
    "            m.addConstr(u[i] >= r[i], name=f\"abs_pos[{i}]\")\n",
    "            m.addConstr(u[i] >= -r[i], name=f\"abs_neg[{i}]\")\n",
    "\n",
    "        # -----------------------\n",
    "        # Routing constraints\n",
    "        # -----------------------\n",
    "        min_dis = self._calMinDist(x)\n",
    "\n",
    "        if self.routing_formulation == \"indicator\":\n",
    "            # Original indicator routing (kept for compatibility).\n",
    "            # NOTE: we do NOT use rdir here; instead we keep your old logic if you want it,\n",
    "            # but indicators require conditioning on \"active\" too. This is exactly why bigM is faster.\n",
    "            #\n",
    "            # If you really want indicator routing, it's better to keep your prior version with rdir.\n",
    "            #\n",
    "            # We'll implement a safe indicator version using bigM gating on d[t] via an aux rdir.\n",
    "            rdir = m.addVars(self.n, self.b_index, vtype=GRB.BINARY, name=\"rdir\")\n",
    "\n",
    "            for t in self.b_index:\n",
    "                rt = 2 * t + 1\n",
    "                for i in range(self.n):\n",
    "                    m.addConstr(rdir[i, t] <= q[i, rt], name=f\"rdir1[{i},{t}]\")\n",
    "                    m.addConstr(rdir[i, t] <= d[t],      name=f\"rdir2[{i},{t}]\")\n",
    "                    m.addConstr(rdir[i, t] >= q[i, rt] + d[t] - 1, name=f\"rdir3[{i},{t}]\")\n",
    "\n",
    "            for t in self.b_index:\n",
    "                lt = 2 * t\n",
    "                for i in range(self.n):\n",
    "                    expr_left = gp.quicksum(a[j, t] * (x[i, j] + float(min_dis[j])) for j in range(self.p))\n",
    "                    m.addGenConstrIndicator(q[i, lt], True, expr_left <= b[t], name=f\"ind_left[{i},{t}]\")\n",
    "\n",
    "                    expr_right = gp.quicksum(a[j, t] * x[i, j] for j in range(self.p))\n",
    "                    m.addGenConstrIndicator(rdir[i, t], True, expr_right >= b[t], name=f\"ind_right[{i},{t}]\")\n",
    "        else:\n",
    "            # Faster: pure linear big-M routing, no rdir.\n",
    "            # Tight global M from feature ranges (safe, usually much faster than many indicators).\n",
    "            feat_min = self.feature_mins_\n",
    "            feat_max = self.feature_maxs_\n",
    "            M_left = float(np.max((feat_max + np.array(min_dis)) - feat_min)) if self.p > 0 else 1.0\n",
    "            M_right = float(np.max(feat_max - feat_min)) if self.p > 0 else 1.0\n",
    "\n",
    "            for t in self.b_index:\n",
    "                lt = 2 * t\n",
    "                rt = 2 * t + 1\n",
    "                for i in range(self.n):\n",
    "                    # If q[i,left]=1 then selected feature value + min_dis <= b[t]\n",
    "                    expr_left = gp.quicksum(a[j, t] * (x[i, j] + float(min_dis[j])) for j in range(self.p))\n",
    "                    m.addConstr(expr_left <= b[t] + M_left * (1 - q[i, lt]), name=f\"bm_left[{i},{t}]\")\n",
    "\n",
    "                    # If q[i,right]=1 AND d[t]=1 then selected feature value >= b[t]\n",
    "                    expr_right = gp.quicksum(a[j, t] * x[i, j] for j in range(self.p))\n",
    "                    # activate only when both are 1: (2 - q_right - d) == 0\n",
    "                    m.addConstr(\n",
    "                        expr_right >= b[t] - M_right * (2 - q[i, rt] - d[t]),\n",
    "                        name=f\"bm_right[{i},{t}]\",\n",
    "                    )\n",
    "\n",
    "        # -----------------------\n",
    "        # Leaf value selection\n",
    "        # -----------------------\n",
    "        if self.leaf_value_formulation == \"indicator\":\n",
    "            for lf in self.l_index:\n",
    "                for i in range(self.n):\n",
    "                    m.addGenConstrIndicator(q[i, lf], True, (s[i] - gamma[lf] == 0.0), name=f\"ind_leafval[{i},{lf}]\")\n",
    "        else:\n",
    "            # Tight big-M using gamma bounds (removes n*L indicators)\n",
    "            M_gamma = float(Upper - Lower)\n",
    "            for i in range(self.n):\n",
    "                for lf in self.l_index:\n",
    "                    m.addConstr(s[i] - gamma[lf] <= M_gamma * (1 - q[i, lf]), name=f\"bm_leaf1[{i},{lf}]\")\n",
    "                    m.addConstr(gamma[lf] - s[i] <= M_gamma * (1 - q[i, lf]), name=f\"bm_leaf2[{i},{lf}]\")\n",
    "\n",
    "        return m, a, b, d, q, l, N, beta, gamma, s, r, u, zsplit\n",
    "\n",
    "    # ---------------------------\n",
    "    # Split candidate computation\n",
    "    # ---------------------------\n",
    "    def _compute_threshold_candidates(self, x: np.ndarray) -> list[np.ndarray]:\n",
    "        \"\"\"\n",
    "        Candidates for b[t] must be interpretable and consistent with your strict-left encoding.\n",
    "        Your encoding effectively uses b[t] as the *minimum value on the right branch*,\n",
    "        so candidates as (unique feature values excluding the minimum) are a good fit.\n",
    "        \"\"\"\n",
    "        cands: list[np.ndarray] = []\n",
    "        for j in range(x.shape[1]):\n",
    "            vals = np.unique(x[:, j].astype(float))\n",
    "            vals = np.sort(vals)\n",
    "            if vals.size <= 1:\n",
    "                cands.append(np.array([0.0], dtype=float))\n",
    "                continue\n",
    "\n",
    "            # exclude minimum: choosing b=min would make left branch infeasible except empty\n",
    "            cand = vals[1:].copy()\n",
    "\n",
    "            if self.max_thresholds is not None and cand.size > self.max_thresholds:\n",
    "                K = self.max_thresholds\n",
    "                if self.threshold_strategy == \"quantile\":\n",
    "                    qs = np.linspace(0.0, 1.0, K)\n",
    "                    cand = np.quantile(cand, qs)\n",
    "                    cand = np.unique(cand)\n",
    "                else:\n",
    "                    # uniform index subsample\n",
    "                    idx = np.linspace(0, cand.size - 1, K).round().astype(int)\n",
    "                    cand = np.unique(cand[idx])\n",
    "\n",
    "            if cand.size == 0:\n",
    "                cand = np.array([vals[-1]], dtype=float)\n",
    "\n",
    "            cands.append(cand.astype(float))\n",
    "        return cands\n",
    "\n",
    "    # ---------------------------\n",
    "    # Warm start\n",
    "    # ---------------------------\n",
    "    def _setStart(self, x, y, a, b, d, q, l, N, beta, gamma, s, r, u, zsplit):\n",
    "        Lower, Upper = self.gamma_bounds\n",
    "        min_dis = self._calMinDist(x)\n",
    "\n",
    "        clf = tree.DecisionTreeRegressor(\n",
    "            max_depth=self.max_depth,\n",
    "            min_samples_leaf=self.min_samples_leaf,\n",
    "            random_state=self.seed,\n",
    "        )\n",
    "        clf.fit(x, y)\n",
    "        rules = self._getRules(clf)\n",
    "\n",
    "        d0 = {t: 0 for t in self.b_index}\n",
    "        b0 = {t: 0.0 for t in self.b_index}\n",
    "        split_feat = {}\n",
    "        cart_thr = {}\n",
    "\n",
    "        for t in self.b_index:\n",
    "            rt = rules[t]\n",
    "            if rt.feat is None or rt.feat == tree._tree.TREE_UNDEFINED:\n",
    "                continue\n",
    "            f = int(rt.feat)\n",
    "            split_feat[t] = f\n",
    "            cart_thr[t] = float(rt.threshold)\n",
    "            d0[t] = 1\n",
    "\n",
    "        # enforce parent-active\n",
    "        for t in self.b_index:\n",
    "            if t != 1 and d0[t] == 1 and d0.get(t // 2, 0) == 0:\n",
    "                d0[t] = 0\n",
    "                split_feat.pop(t, None)\n",
    "                cart_thr.pop(t, None)\n",
    "\n",
    "        # choose feasible b0 under strict-left encoding\n",
    "        left_vals = {t: [] for t in split_feat}\n",
    "        right_vals = {t: [] for t in split_feat}\n",
    "\n",
    "        for i in range(self.n):\n",
    "            t = 1\n",
    "            while t not in self.l_index:\n",
    "                if d0.get(t, 0) == 0:\n",
    "                    t = 2 * t + 1\n",
    "                    continue\n",
    "                f = split_feat[t]\n",
    "                thr = cart_thr[t]\n",
    "                val = x[i, f]\n",
    "                if val + self.eps_tie >= thr:\n",
    "                    right_vals[t].append(val)\n",
    "                    t = 2 * t + 1\n",
    "                else:\n",
    "                    left_vals[t].append(val)\n",
    "                    t = 2 * t\n",
    "\n",
    "        for t in list(split_feat.keys()):\n",
    "            f = split_feat[t]\n",
    "            if len(left_vals[t]) == 0 or len(right_vals[t]) == 0:\n",
    "                d0[t] = 0\n",
    "                split_feat.pop(t, None)\n",
    "                cart_thr.pop(t, None)\n",
    "                continue\n",
    "            rmin = float(np.min(right_vals[t]))\n",
    "            lmax = float(np.max(left_vals[t]))\n",
    "            if lmax + float(min_dis[f]) > rmin + 1e-12:\n",
    "                d0[t] = 0\n",
    "                split_feat.pop(t, None)\n",
    "                cart_thr.pop(t, None)\n",
    "                continue\n",
    "            b0[t] = rmin\n",
    "\n",
    "        # enforce parent-active again\n",
    "        for t in self.b_index:\n",
    "            if t != 1 and d0.get(t, 0) == 1 and d0.get(t // 2, 0) == 0:\n",
    "                d0[t] = 0\n",
    "                split_feat.pop(t, None)\n",
    "                cart_thr.pop(t, None)\n",
    "                b0[t] = 0.0\n",
    "\n",
    "        # beta start\n",
    "        try:\n",
    "            beta_start = np.linalg.lstsq(x, y, rcond=None)[0]\n",
    "        except np.linalg.LinAlgError:\n",
    "            beta_start = np.zeros(self.p, dtype=float)\n",
    "\n",
    "        if self.beta_bounds is not None:\n",
    "            lb, ub = self.beta_bounds\n",
    "            beta_start = np.clip(beta_start, lb, ub)\n",
    "\n",
    "        residuals = y - x @ beta_start\n",
    "\n",
    "        def route_leaf(xi):\n",
    "            t = 1\n",
    "            while t not in self.l_index:\n",
    "                if d0.get(t, 0) == 0:\n",
    "                    t = 2 * t + 1\n",
    "                    continue\n",
    "                f = split_feat[t]\n",
    "                thr = b0[t]\n",
    "                if xi[f] + self.eps_tie >= thr:\n",
    "                    t = 2 * t + 1\n",
    "                else:\n",
    "                    t = 2 * t\n",
    "            return t\n",
    "\n",
    "        assignments = [route_leaf(x[i, :]) for i in range(self.n)]\n",
    "\n",
    "        leaf_counts = {lf: 0 for lf in self.l_index}\n",
    "        res_by_leaf = {lf: [] for lf in self.l_index}\n",
    "        for i, lf in enumerate(assignments):\n",
    "            leaf_counts[lf] += 1\n",
    "            res_by_leaf[lf].append(float(residuals[i]))\n",
    "\n",
    "        if any((cnt > 0 and cnt < self.min_samples_leaf) for cnt in leaf_counts.values()):\n",
    "            # fallback: single leaf\n",
    "            self._seed_single_leaf_start(x, y, beta_start, residuals, a, b, d, q, l, N, beta, gamma, s, r, u, zsplit)\n",
    "            return\n",
    "\n",
    "        # write starts for splits\n",
    "        # if using zsplit (discrete thresholds), we must seed those too\n",
    "        for t in self.b_index:\n",
    "            if d0.get(t, 0) == 0:\n",
    "                d[t].Start = 0\n",
    "                b[t].Start = 0.0\n",
    "                for f in range(self.p):\n",
    "                    a[f, t].Start = 0\n",
    "            else:\n",
    "                d[t].Start = 1\n",
    "                fsel = split_feat[t]\n",
    "                for f in range(self.p):\n",
    "                    a[f, t].Start = 1 if f == fsel else 0\n",
    "\n",
    "                # threshold start\n",
    "                bt = float(b0[t])\n",
    "                if zsplit is None:\n",
    "                    b[t].Start = bt\n",
    "                else:\n",
    "                    # project bt to nearest candidate >= bt (safe for strict-left encoding)\n",
    "                    cand = self._threshold_candidates_[fsel]\n",
    "                    idx = int(np.searchsorted(cand, bt, side=\"left\"))\n",
    "                    if idx >= len(cand):\n",
    "                        idx = len(cand) - 1\n",
    "                    b[t].Start = float(cand[idx])\n",
    "\n",
    "        # seed zsplit vars if present\n",
    "        if zsplit is not None:\n",
    "            # default 0\n",
    "            for (j, k, t) in zsplit.keys():\n",
    "                zsplit[j, k, t].Start = 0\n",
    "\n",
    "            for t in self.b_index:\n",
    "                if d0.get(t, 0) == 0:\n",
    "                    continue\n",
    "                fsel = split_feat[t]\n",
    "                bt = float(b[t].Start)\n",
    "                cand = self._threshold_candidates_[fsel]\n",
    "                ksel = int(np.searchsorted(cand, bt, side=\"left\"))\n",
    "                ksel = min(ksel, len(cand) - 1)\n",
    "                zsplit[fsel, ksel, t].Start = 1\n",
    "\n",
    "        for j in range(self.p):\n",
    "            beta[j].Start = float(beta_start[j])\n",
    "\n",
    "        gamma0 = {}\n",
    "        for lf in self.l_index:\n",
    "            g = float(np.median(res_by_leaf[lf])) if leaf_counts[lf] > 0 else 0.0\n",
    "            g = float(np.clip(g, Lower, Upper))\n",
    "            gamma[lf].Start = g\n",
    "            gamma0[lf] = g\n",
    "            l[lf].Start = 1 if leaf_counts[lf] > 0 else 0\n",
    "            N[lf].Start = float(leaf_counts[lf])\n",
    "\n",
    "        # q starts\n",
    "        for i in range(self.n):\n",
    "            for t in self.n_index:\n",
    "                q[i, t].Start = 0\n",
    "            q[i, 1].Start = 1\n",
    "\n",
    "            t = 1\n",
    "            while t not in self.l_index:\n",
    "                if d0.get(t, 0) == 0:\n",
    "                    rt = 2 * t + 1\n",
    "                    q[i, rt].Start = 1\n",
    "                    t = rt\n",
    "                    continue\n",
    "\n",
    "                f = split_feat[t]\n",
    "                thr = float(b[t].Start)\n",
    "                if x[i, f] + self.eps_tie >= thr:\n",
    "                    rt = 2 * t + 1\n",
    "                    q[i, rt].Start = 1\n",
    "                    t = rt\n",
    "                else:\n",
    "                    lt = 2 * t\n",
    "                    q[i, lt].Start = 1\n",
    "                    t = lt\n",
    "\n",
    "            lf = t\n",
    "            sval = gamma0[lf]\n",
    "            s[i].Start = sval\n",
    "\n",
    "            ri = float(residuals[i] - sval)\n",
    "            r[i].Start = ri\n",
    "            u[i].Start = abs(ri)\n",
    "\n",
    "    def _seed_single_leaf_start(self, x, y, beta_start, residuals, a, b, d, q, l, N, beta, gamma, s, r, u, zsplit):\n",
    "        Lower, Upper = self.gamma_bounds\n",
    "        default_leaf = self.l_index[-1]\n",
    "        gval = float(np.clip(np.median(residuals), Lower, Upper)) if self.n > 0 else 0.0\n",
    "\n",
    "        for t in self.b_index:\n",
    "            d[t].Start = 0\n",
    "            b[t].Start = 0.0\n",
    "            for f in range(self.p):\n",
    "                a[f, t].Start = 0\n",
    "\n",
    "        if zsplit is not None:\n",
    "            for key in zsplit.keys():\n",
    "                zsplit[key].Start = 0\n",
    "\n",
    "        for j in range(self.p):\n",
    "            beta[j].Start = float(beta_start[j])\n",
    "\n",
    "        for lf in self.l_index:\n",
    "            l[lf].Start = 1 if lf == default_leaf else 0\n",
    "            N[lf].Start = float(self.n) if lf == default_leaf else 0.0\n",
    "            gamma[lf].Start = gval if lf == default_leaf else 0.0\n",
    "\n",
    "        for i in range(self.n):\n",
    "            for t in self.n_index:\n",
    "                q[i, t].Start = 0\n",
    "            q[i, 1].Start = 1\n",
    "\n",
    "            t = 1\n",
    "            while t not in self.l_index:\n",
    "                t = 2 * t + 1\n",
    "                q[i, t].Start = 1\n",
    "\n",
    "            s[i].Start = gval\n",
    "            ri = float(residuals[i] - gval)\n",
    "            r[i].Start = ri\n",
    "            u[i].Start = abs(ri)\n",
    "\n",
    "    # ---------------------------\n",
    "    # Fast polish step\n",
    "    # ---------------------------\n",
    "    def _polish_solution(self, m: gp.Model, *, a, d, q, l, zsplit):\n",
    "        \"\"\"\n",
    "        Fix binaries to incumbent (rounded) and re-optimize continuous vars as LP.\n",
    "        This is typically very fast and can noticeably improve objective quality\n",
    "        when the MIP is stopped early.\n",
    "        \"\"\"\n",
    "        # Collect binaries\n",
    "        binaries = []\n",
    "        for t in self.b_index:\n",
    "            binaries.append(d[t])\n",
    "            for j in range(self.p):\n",
    "                binaries.append(a[j, t])\n",
    "        for i in range(self.n):\n",
    "            for t in self.n_index:\n",
    "                binaries.append(q[i, t])\n",
    "        for lf in self.l_index:\n",
    "            binaries.append(l[lf])\n",
    "        if zsplit is not None:\n",
    "            for key in zsplit.keys():\n",
    "                binaries.append(zsplit[key])\n",
    "\n",
    "        # Fix them\n",
    "        for v in binaries:\n",
    "            val = 1.0 if v.X >= 0.5 else 0.0\n",
    "            v.LB = val\n",
    "            v.UB = val\n",
    "\n",
    "        m.update()\n",
    "\n",
    "        # Re-optimize (LP)\n",
    "        old_tl = m.Params.TimeLimit\n",
    "        m.Params.TimeLimit = max(0.0, float(self.polish_timelimit))\n",
    "        m.optimize()\n",
    "        m.Params.TimeLimit = old_tl\n",
    "\n",
    "    # ---------------------------\n",
    "    # Utilities\n",
    "    # ---------------------------\n",
    "    @staticmethod\n",
    "    def _calMinDist(x: np.ndarray):\n",
    "        min_dis = []\n",
    "        for j in range(x.shape[1]):\n",
    "            xj = np.unique(x[:, j])\n",
    "            if len(xj) <= 1:\n",
    "                min_dis.append(1.0)\n",
    "                continue\n",
    "            xj = np.sort(xj)\n",
    "            diffs = np.diff(xj)\n",
    "            diffs = diffs[diffs > 0]\n",
    "            min_dis.append(float(np.min(diffs)) if diffs.size else 1.0)\n",
    "        return min_dis\n",
    "\n",
    "    def _getRules(self, clf):\n",
    "        node_map = {1: 0}\n",
    "        for t in self.b_index:\n",
    "            node_map[2 * t] = -1\n",
    "            node_map[2 * t + 1] = -1\n",
    "            if node_map[t] == -1:\n",
    "                continue\n",
    "            node_map[2 * t] = clf.tree_.children_left[node_map[t]]\n",
    "            node_map[2 * t + 1] = clf.tree_.children_right[node_map[t]]\n",
    "\n",
    "        rule = namedtuple(\"Rules\", (\"feat\", \"threshold\", \"value\"))\n",
    "        rules = {}\n",
    "        for t in self.b_index:\n",
    "            i = node_map[t]\n",
    "            rules[t] = rule(None, None, None) if i == -1 else rule(\n",
    "                clf.tree_.feature[i], clf.tree_.threshold[i], clf.tree_.value[i, 0]\n",
    "            )\n",
    "        for t in self.l_index:\n",
    "            i = node_map[t]\n",
    "            rules[t] = rule(None, None, None) if i == -1 else rule(None, None, clf.tree_.value[i, 0])\n",
    "        return rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae477cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== diabetes_sklearn ===\n",
      "LinearRegression RMSE=38.0990  MAE=28.5090  R2=0.6989  fit_s=0.01\n",
      "Ridge(alpha=1.0) RMSE=39.4934  MAE=31.4610  R2=0.6764  fit_s=0.00\n",
      "Lasso(alpha=0.01) RMSE=38.1176  MAE=28.4796  R2=0.6986  fit_s=0.00\n",
      "CART             RMSE=64.4963  MAE=58.8462  R2=0.1370  fit_s=0.00\n",
      "RandomForest     RMSE=44.0890  MAE=38.8672  R2=0.5967  fit_s=0.30\n",
      "ExtraTrees       RMSE=48.1208  MAE=40.9398  R2=0.5196  fit_s=0.24\n",
      "GradientBoosting RMSE=50.8034  MAE=45.3818  R2=0.4645  fit_s=0.02\n",
      "Training data include 37 instances, 10 features.\n",
      "Set parameter WLSAccessID\n",
      "Set parameter WLSSecret\n",
      "Set parameter LicenseID to value 2755804\n",
      "Academic license 2755804 - for non-commercial use only - registered to pa___@mit.edu\n",
      "Set parameter OutputFlag to value 1\n",
      "Set parameter LogToConsole to value 1\n",
      "Set parameter TimeLimit to value 300\n",
      "Set parameter Threads to value 0\n",
      "Set parameter Seed to value 0\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (armlinux64 - \"Ubuntu 24.04.2 LTS\")\n",
      "\n",
      "CPU model: ARM64\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  300\n",
      "\n",
      "Academic license 2755804 - for non-commercial use only - registered to pa___@mit.edu\n",
      "Optimize a model with 4962 rows, 5201 columns and 36235 nonzeros (Min)\n",
      "Model fingerprint: 0x6b053f58\n",
      "Model has 52 linear objective coefficients\n",
      "Variable types: 168 continuous, 5033 integer (5033 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [5e-03, 1e+01]\n",
      "  Objective range  [1e-03, 3e-02]\n",
      "  Bounds range     [1e+00, 5e+00]\n",
      "  RHS range        [4e-02, 1e+01]\n",
      "Presolve removed 956 rows and 401 columns\n",
      "Presolve time: 0.12s\n",
      "Presolved: 4006 rows, 4800 columns, 29368 nonzeros\n",
      "Variable types: 152 continuous, 4648 integer (4648 binary)\n",
      "Found heuristic solution: objective 0.5262267\n",
      "\n",
      "Root relaxation: objective 2.632038e-01, 661 iterations, 0.03 seconds (0.02 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    0.26320    0  116    0.52623    0.26320  50.0%     -    0s\n",
      "     0     0    0.26320    0  185    0.52623    0.26320  50.0%     -    0s\n",
      "     0     0    0.26320    0  185    0.52623    0.26320  50.0%     -    0s\n",
      "     0     0    0.26320    0  185    0.52623    0.26320  50.0%     -    0s\n",
      "     0     0    0.26320    0  185    0.52623    0.26320  50.0%     -    0s\n",
      "     0     0    0.26320    0  185    0.52623    0.26320  50.0%     -    0s\n",
      "     0     0    0.26320    0  185    0.52623    0.26320  50.0%     -    0s\n",
      "     0     0    0.26320    0  185    0.52623    0.26320  50.0%     -    0s\n",
      "     0     0    0.26320    0  185    0.52623    0.26320  50.0%     -    0s\n",
      "     0     0    0.26320    0  185    0.52623    0.26320  50.0%     -    0s\n",
      "     0     0    0.26320    0  185    0.52623    0.26320  50.0%     -    0s\n",
      "H    0     0                       0.5103079    0.26320  48.4%     -    0s\n",
      "     0     0    0.26411    0   99    0.51031    0.26411  48.2%     -    0s\n",
      "     0     0    0.26411    0   95    0.51031    0.26411  48.2%     -    0s\n",
      "     0     0    0.26411    0  109    0.51031    0.26411  48.2%     -    0s\n",
      "     0     0    0.26411    0  109    0.51031    0.26411  48.2%     -    0s\n",
      "     0     0    0.26411    0  118    0.51031    0.26411  48.2%     -    0s\n",
      "     0     0    0.26411    0  116    0.51031    0.26411  48.2%     -    0s\n",
      "     0     0    0.26411    0  118    0.51031    0.26411  48.2%     -    0s\n",
      "     0     0    0.26411    0  117    0.51031    0.26411  48.2%     -    0s\n",
      "     0     0    0.26411    0  117    0.51031    0.26411  48.2%     -    0s\n",
      "     0     0    0.26411    0  118    0.51031    0.26411  48.2%     -    0s\n",
      "     0     0    0.26411    0  117    0.51031    0.26411  48.2%     -    0s\n",
      "     0     0    0.26411    0  118    0.51031    0.26411  48.2%     -    0s\n",
      "     0     0    0.26411    0  118    0.51031    0.26411  48.2%     -    0s\n",
      "     0     0    0.26411    0  118    0.51031    0.26411  48.2%     -    0s\n",
      "     0     0    0.26411    0  118    0.51031    0.26411  48.2%     -    0s\n",
      "     0     0    0.26411    0  118    0.51031    0.26411  48.2%     -    0s\n",
      "     0     0    0.26411    0  118    0.51031    0.26411  48.2%     -    0s\n",
      "     0     0    0.26431    0  113    0.51031    0.26431  48.2%     -    0s\n",
      "     0     0    0.26431    0  104    0.51031    0.26431  48.2%     -    0s\n",
      "     0     0    0.26511    0   96    0.51031    0.26511  48.0%     -    0s\n",
      "     0     0    0.26511    0   90    0.51031    0.26511  48.0%     -    0s\n",
      "     0     0    0.26511    0  117    0.51031    0.26511  48.0%     -    0s\n",
      "     0     0    0.26511    0  118    0.51031    0.26511  48.0%     -    0s\n",
      "     0     0    0.26511    0  117    0.51031    0.26511  48.0%     -    0s\n",
      "     0     0    0.26511    0  113    0.51031    0.26511  48.0%     -    0s\n",
      "     0     0    0.26511    0  118    0.51031    0.26511  48.0%     -    0s\n",
      "     0     0    0.26511    0  115    0.51031    0.26511  48.0%     -    0s\n",
      "     0     0    0.26511    0  114    0.51031    0.26511  48.0%     -    0s\n",
      "     0     0    0.26511    0  114    0.51031    0.26511  48.0%     -    0s\n",
      "     0     0    0.26511    0  115    0.51031    0.26511  48.0%     -    0s\n",
      "     0     0    0.26511    0   92    0.51031    0.26511  48.0%     -    0s\n",
      "     0     0    0.26511    0  113    0.51031    0.26511  48.0%     -    0s\n",
      "     0     0    0.26511    0  113    0.51031    0.26511  48.0%     -    0s\n",
      "     0     0    0.26511    0  113    0.51031    0.26511  48.0%     -    0s\n",
      "     0     0    0.26511    0  112    0.51031    0.26511  48.0%     -    0s\n",
      "     0     0    0.26511    0  107    0.51031    0.26511  48.0%     -    1s\n",
      "     0     0    0.26511    0  104    0.51031    0.26511  48.0%     -    1s\n",
      "     0     0    0.26511    0  122    0.51031    0.26511  48.0%     -    1s\n",
      "     0     0    0.26511    0  114    0.51031    0.26511  48.0%     -    1s\n",
      "     0     0    0.26511    0  116    0.51031    0.26511  48.0%     -    1s\n",
      "     0     0    0.26511    0  114    0.51031    0.26511  48.0%     -    1s\n",
      "     0     0    0.26511    0  114    0.51031    0.26511  48.0%     -    1s\n",
      "     0     0    0.26511    0  114    0.51031    0.26511  48.0%     -    1s\n",
      "     0     0    0.26511    0  114    0.51031    0.26511  48.0%     -    1s\n",
      "     0     0    0.26511    0  116    0.51031    0.26511  48.0%     -    1s\n",
      "     0     0    0.26511    0  114    0.51031    0.26511  48.0%     -    1s\n",
      "     0     0    0.26511    0  114    0.51031    0.26511  48.0%     -    1s\n",
      "     0     0    0.26511    0  119    0.51031    0.26511  48.0%     -    1s\n",
      "     0     0    0.26511    0  119    0.51031    0.26511  48.0%     -    1s\n",
      "     0     0    0.26511    0  114    0.51031    0.26511  48.0%     -    1s\n",
      "     0     0    0.26511    0  114    0.51031    0.26511  48.0%     -    1s\n",
      "     0     2    0.26511    0  114    0.51031    0.26511  48.0%     -    1s\n",
      "H   34    32                       0.4990837    0.26511  46.9%   109    1s\n",
      "H  536   319                       0.4749299    0.26511  44.2%  57.7    1s\n",
      "  3190  1469    0.26611   19  294    0.47493    0.26534  44.1%  53.0    5s\n",
      "  4692  1646    0.28338   30  141    0.47493    0.26611  44.0%  66.6   10s\n",
      "  5624  1647    0.47080   28   32    0.47493    0.26611  44.0%  70.8   15s\n",
      "  9573  2517    0.32996   37  129    0.47493    0.26728  43.7%  79.5   20s\n",
      " 12892  3443 infeasible   40         0.47493    0.26931  43.3%  79.1   25s\n",
      " 14444  3843    0.38445   31   93    0.47493    0.28645  39.7%  78.6   30s\n",
      " 16399  4419    0.31896   36  174    0.47493    0.30013  36.8%  78.8   37s\n",
      " 17215  4545    0.41079   37   48    0.47493    0.30088  36.6%  78.5   40s\n",
      " 22910  5480 infeasible   37         0.47493    0.30529  35.7%  76.3   45s\n",
      " 30740  6771 infeasible   45         0.47493    0.32006  32.6%  75.4   50s\n",
      " 35917  7142    0.43381   34  114    0.47493    0.32729  31.1%  74.4   67s\n",
      " 35923  7146    0.33518   33  241    0.47493    0.32729  31.1%  74.4   70s\n",
      " 35927  7149    0.35004   34  295    0.47493    0.32729  31.1%  74.4   75s\n",
      " 35932  7152    0.38508   38  266    0.47493    0.32729  31.1%  74.4   80s\n",
      " 35937  7155    0.33651   36  278    0.47493    0.32729  31.1%  74.4   85s\n",
      " 36273  7213    0.38541   35   85    0.47493    0.32729  31.1%  75.7   90s\n",
      " 37718  7245    0.32729   39  199    0.47493    0.32729  31.1%  77.1   95s\n",
      " 40277  7257     cutoff   50         0.47493    0.32729  31.1%  78.6  101s\n",
      " 40861  7265    0.43578   43   74    0.47493    0.32729  31.1%  79.1  105s\n",
      " 43652  7092    0.39845   43   57    0.47493    0.32729  31.1%  79.4  110s\n",
      " 44815  6907 infeasible   46         0.47493    0.32729  31.1%  79.4  116s\n",
      " 45864  6861 infeasible   49         0.47493    0.32729  31.1%  79.2  120s\n",
      " 49387  6517    0.32729   50  138    0.47493    0.32729  31.1%  80.1  125s\n",
      " 52747  6109    0.39680   57   95    0.47493    0.32729  31.1%  80.2  131s\n",
      " 53656  6069    0.41175   48   69    0.47493    0.32729  31.1%  80.4  136s\n",
      " 56386  5832    0.32729   48   95    0.47493    0.32729  31.1%  80.7  140s\n",
      " 58158  7118    0.39667   52   47    0.47493    0.32729  31.1%  80.7  145s\n",
      " 65728  7755    0.45449   44   50    0.47493    0.32729  31.1%  77.9  151s\n",
      " 70652  8980    0.42064   58   39    0.47493    0.33041  30.4%  76.9  156s\n",
      " 72067  9361 infeasible   51         0.47493    0.33049  30.4%  77.2  162s\n",
      " 73264 10400    0.39870   41   69    0.47493    0.33130  30.2%  77.3  165s\n",
      " 80477 11183    0.45963   57   55    0.47493    0.33352  29.8%  75.7  170s\n",
      " 83506 11533    0.39844   52   82    0.47493    0.33492  29.5%  75.7  175s\n",
      " 89973 12985    0.40432   50   81    0.47493    0.34067  28.3%  74.9  180s\n",
      " 96638 14890    0.35644   54  103    0.47493    0.34519  27.3%  75.1  186s\n",
      " 103367 15468    0.39011   49   73    0.47493    0.34728  26.9%  74.2  190s\n",
      " 108094 15852    0.35529   50  203    0.47493    0.35034  26.2%  74.2  200s\n",
      " 118496 17494    0.47101   49   26    0.47493    0.35816  24.6%  73.0  205s\n",
      " 122623 18093     cutoff   54         0.47493    0.35962  24.3%  72.5  210s\n",
      " 126132 18375     cutoff   49         0.47493    0.36249  23.7%  72.3  218s\n",
      " 127255 18526    0.39708   65   52    0.47493    0.36419  23.3%  72.3  221s\n",
      " 135401 19110    0.44575   43   54    0.47493    0.36972  22.2%  72.2  225s\n",
      " 144784 20713    0.41017   58   90    0.47493    0.37212  21.6%  71.3  236s\n",
      " 145788 20867    0.37312   47   60    0.47493    0.37267  21.5%  71.4  240s\n",
      " 154395 21355    0.40972   48   70    0.47493    0.37589  20.9%  71.2  245s\n",
      " 161573 22415    0.47409   73   31    0.47493    0.37972  20.0%  71.1  250s\n",
      " 167051 22336    0.42785   48   82    0.47493    0.38104  19.8%  70.3  257s\n",
      " 167718 22330    0.47203   58   32    0.47493    0.38107  19.8%  70.3  260s\n",
      " 176675 22548    0.38733   61   82    0.47493    0.38686  18.5%  70.2  265s\n",
      " 181272 22939    0.43896   52   34    0.47493    0.38806  18.3%  70.6  270s\n",
      " 183347 23083    0.42396   43   44    0.47493    0.38865  18.2%  70.8  277s\n",
      " 184495 23180    0.38927   54   87    0.47493    0.38890  18.1%  70.8  280s\n",
      " 189169 23423    0.42256   65   68    0.47493    0.38968  18.0%  71.1  285s\n",
      " 197356 23539     cutoff   62         0.47493    0.39165  17.5%  71.2  290s\n",
      " 200219 23438    0.43233   56   57    0.47493    0.39256  17.3%  71.2  296s\n",
      " 201853 23376    0.39498   47   53    0.47493    0.39356  17.1%  71.2  300s\n",
      "\n",
      "Cutting planes:\n",
      "  Learned: 2\n",
      "  Gomory: 8\n",
      "  Lift-and-project: 1\n",
      "  Cover: 76\n",
      "  Implied bound: 12\n",
      "  Clique: 26\n",
      "  MIR: 31\n",
      "  StrongCG: 12\n",
      "  Flow cover: 87\n",
      "  GUB cover: 19\n",
      "  Inf proof: 1\n",
      "  Zero half: 5\n",
      "  RLT: 2\n",
      "  Relax-and-lift: 2\n",
      "  BQP: 5\n",
      "\n",
      "Explored 203004 nodes (14462626 simplex iterations) in 300.15 seconds (346.34 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 4: 0.47493 0.499084 0.510308 0.526227 \n",
      "\n",
      "Time limit reached\n",
      "Best objective 4.749299378157e-01, best bound 3.940828219065e-01, gap 17.0230%\n",
      "Set parameter TimeLimit to value 10\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (armlinux64 - \"Ubuntu 24.04.2 LTS\")\n",
      "\n",
      "CPU model: ARM64\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  10\n",
      "\n",
      "Academic license 2755804 - for non-commercial use only - registered to pa___@mit.edu\n",
      "Optimize a model with 4962 rows, 5201 columns and 36235 nonzeros (Min)\n",
      "Model fingerprint: 0xd2ae6ea0\n",
      "Model has 52 linear objective coefficients\n",
      "Variable types: 168 continuous, 5033 integer (5033 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [5e-03, 1e+01]\n",
      "  Objective range  [1e-03, 3e-02]\n",
      "  Bounds range     [1e+00, 5e+00]\n",
      "  RHS range        [4e-02, 1e+01]\n",
      "\n",
      "MIP start from previous solve produced solution with objective 0.47493 (0.02s)\n",
      "Loaded MIP start from previous solve with objective 0.47493\n",
      "\n",
      "Presolve removed 4851 rows and 5114 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 111 rows, 87 columns, 592 nonzeros\n",
      "Variable types: 87 continuous, 0 integer (0 binary)\n",
      "\n",
      "Root relaxation: cutoff, 54 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0     cutoff    0         0.47493    0.47493  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (54 simplex iterations) in 0.04 seconds (0.01 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 0.47493 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 4.749299378157e-01, best bound 4.749299378157e-01, gap 0.0000%\n",
      "Set parameter TimeLimit to value 300\n",
      "IORFA            RMSE=47.2808  MAE=40.4667  R2=0.5362  fit_s=302.32  gap=0.0  status=2\n",
      "\n",
      "=== california_housing_sklearn ===\n",
      "LinearRegression RMSE=0.9849  MAE=0.7470  R2=0.4790  fit_s=0.01\n",
      "Ridge(alpha=1.0) RMSE=1.0212  MAE=0.7460  R2=0.4398  fit_s=0.01\n",
      "Lasso(alpha=0.01) RMSE=0.9972  MAE=0.7445  R2=0.4659  fit_s=0.00\n",
      "CART             RMSE=1.0237  MAE=0.8158  R2=0.4372  fit_s=0.00\n",
      "RandomForest     RMSE=0.8288  MAE=0.5990  R2=0.6311  fit_s=0.28\n",
      "ExtraTrees       RMSE=0.9072  MAE=0.6750  R2=0.5579  fit_s=0.29\n",
      "GradientBoosting RMSE=0.8265  MAE=0.6038  R2=0.6331  fit_s=0.04\n",
      "Training data include 37 instances, 8 features.\n",
      "Set parameter OutputFlag to value 1\n",
      "Set parameter LogToConsole to value 1\n",
      "Set parameter TimeLimit to value 300\n",
      "Set parameter Threads to value 0\n",
      "Set parameter Seed to value 0\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (armlinux64 - \"Ubuntu 24.04.2 LTS\")\n",
      "\n",
      "CPU model: ARM64\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  300\n",
      "\n",
      "Academic license 2755804 - for non-commercial use only - registered to pa___@mit.edu\n",
      "Optimize a model with 4932 rows, 5169 columns and 33911 nonzeros (Min)\n",
      "Model fingerprint: 0xd75aa87d\n",
      "Model has 52 linear objective coefficients\n",
      "Variable types: 166 continuous, 5003 integer (5003 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [4e-03, 1e+01]\n",
      "  Objective range  [1e-03, 3e-02]\n",
      "  Bounds range     [1e+00, 5e+00]\n",
      "  RHS range        [3e-02, 1e+01]\n",
      "Presolve removed 941 rows and 386 columns\n",
      "Presolve time: 0.10s\n",
      "Presolved: 3991 rows, 4783 columns, 25304 nonzeros\n",
      "Variable types: 150 continuous, 4633 integer (4633 binary)\n",
      "Found heuristic solution: objective 0.3860790\n",
      "Found heuristic solution: objective 0.3790790\n",
      "\n",
      "Root relaxation: objective 1.896346e-01, 708 iterations, 0.02 seconds (0.02 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    0.18963    0  191    0.37908    0.18963  50.0%     -    0s\n",
      "     0     0    0.18963    0  118    0.37908    0.18963  50.0%     -    0s\n",
      "     0     0    0.18963    0  118    0.37908    0.18963  50.0%     -    0s\n",
      "     0     0    0.18963    0  118    0.37908    0.18963  50.0%     -    0s\n",
      "     0     0    0.18963    0  118    0.37908    0.18963  50.0%     -    0s\n",
      "     0     0    0.18963    0  118    0.37908    0.18963  50.0%     -    0s\n",
      "     0     0    0.18963    0  118    0.37908    0.18963  50.0%     -    0s\n",
      "     0     0    0.18963    0  118    0.37908    0.18963  50.0%     -    0s\n",
      "     0     0    0.18963    0  118    0.37908    0.18963  50.0%     -    0s\n",
      "     0     0    0.18963    0  118    0.37908    0.18963  50.0%     -    0s\n",
      "     0     0    0.18963    0  118    0.37908    0.18963  50.0%     -    0s\n",
      "H    0     0                       0.3743365    0.18963  49.3%     -    0s\n",
      "     0     0    0.19054    0  139    0.37434    0.19054  49.1%     -    0s\n",
      "     0     0    0.19054    0  139    0.37434    0.19054  49.1%     -    0s\n",
      "     0     0    0.19054    0  140    0.37434    0.19054  49.1%     -    0s\n",
      "     0     0    0.19054    0  140    0.37434    0.19054  49.1%     -    0s\n",
      "     0     0    0.19054    0  140    0.37434    0.19054  49.1%     -    0s\n",
      "     0     0    0.19054    0  140    0.37434    0.19054  49.1%     -    0s\n",
      "     0     0    0.19054    0  140    0.37434    0.19054  49.1%     -    0s\n",
      "     0     0    0.19054    0  140    0.37434    0.19054  49.1%     -    0s\n",
      "     0     0    0.19054    0  140    0.37434    0.19054  49.1%     -    0s\n",
      "     0     0    0.19054    0  140    0.37434    0.19054  49.1%     -    0s\n",
      "     0     0    0.19054    0  140    0.37434    0.19054  49.1%     -    0s\n",
      "     0     0    0.19063    0  147    0.37434    0.19063  49.1%     -    0s\n",
      "     0     0    0.19063    0  147    0.37434    0.19063  49.1%     -    0s\n",
      "     0     0    0.19063    0  147    0.37434    0.19063  49.1%     -    0s\n",
      "     0     0    0.19063    0  147    0.37434    0.19063  49.1%     -    0s\n",
      "     0     0    0.19063    0  147    0.37434    0.19063  49.1%     -    0s\n",
      "     0     0    0.19063    0  147    0.37434    0.19063  49.1%     -    0s\n",
      "     0     0    0.19063    0  144    0.37434    0.19063  49.1%     -    0s\n",
      "     0     0    0.19154    0  120    0.37434    0.19154  48.8%     -    1s\n",
      "     0     0    0.19154    0  120    0.37434    0.19154  48.8%     -    1s\n",
      "     0     0    0.19154    0  117    0.37434    0.19154  48.8%     -    1s\n",
      "     0     0    0.19154    0  115    0.37434    0.19154  48.8%     -    1s\n",
      "     0     0    0.19154    0  117    0.37434    0.19154  48.8%     -    1s\n",
      "     0     0    0.19154    0  118    0.37434    0.19154  48.8%     -    1s\n",
      "     0     0    0.19154    0  118    0.37434    0.19154  48.8%     -    1s\n",
      "     0     0    0.19154    0  118    0.37434    0.19154  48.8%     -    1s\n",
      "     0     0    0.19154    0  115    0.37434    0.19154  48.8%     -    1s\n",
      "     0     0    0.19154    0  103    0.37434    0.19154  48.8%     -    1s\n",
      "     0     0    0.19156    0  103    0.37434    0.19156  48.8%     -    1s\n",
      "     0     0    0.19156    0  102    0.37434    0.19156  48.8%     -    1s\n",
      "     0     0    0.19156    0  102    0.37434    0.19156  48.8%     -    1s\n",
      "     0     0    0.19156    0  102    0.37434    0.19156  48.8%     -    1s\n",
      "     0     0    0.19156    0  102    0.37434    0.19156  48.8%     -    1s\n",
      "     0     0    0.19156    0  102    0.37434    0.19156  48.8%     -    1s\n",
      "     0     0    0.19156    0  108    0.37434    0.19156  48.8%     -    1s\n",
      "     0     0    0.19161    0  118    0.37434    0.19161  48.8%     -    1s\n",
      "     0     0    0.19161    0  118    0.37434    0.19161  48.8%     -    1s\n",
      "     0     0    0.19161    0  118    0.37434    0.19161  48.8%     -    1s\n",
      "     0     0    0.19163    0  120    0.37434    0.19163  48.8%     -    1s\n",
      "     0     0    0.19164    0  119    0.37434    0.19164  48.8%     -    1s\n",
      "     0     0    0.19164    0  103    0.37434    0.19164  48.8%     -    1s\n",
      "     0     0    0.19199    0   99    0.37434    0.19199  48.7%     -    1s\n",
      "     0     0    0.19199    0   99    0.37434    0.19199  48.7%     -    1s\n",
      "     0     2    0.19199    0   99    0.37434    0.19199  48.7%     -    1s\n",
      "* 1592   713              56       0.3604611    0.19199  46.7%  49.0    2s\n",
      "H 1742   754                       0.3594611    0.19199  46.6%  49.3    2s\n",
      "H 3070  1247                       0.3574611    0.19199  46.3%  47.4    3s\n",
      "  3076  1251    0.19272   11  235    0.35746    0.19199  46.3%  47.3    5s\n",
      "  6212  1319    0.24146   38  104    0.35746    0.19286  46.0%  60.6   10s\n",
      " 13566  3127    0.20670   38  116    0.35746    0.19454  45.6%  63.3   15s\n",
      " 17691  3907 infeasible   39         0.35746    0.19469  45.5%  63.8   22s\n",
      " 19224  4147    0.28656   40   32    0.35746    0.19489  45.5%  64.0   26s\n",
      " 21845  4791 infeasible   45         0.35746    0.19506  45.4%  64.2   30s\n",
      " 33567  6091     cutoff   39         0.35746    0.21254  40.5%  62.7   35s\n",
      " 35483  6092    0.25356   38   99    0.35746    0.21507  39.8%  62.2   45s\n",
      " 35492  6098    0.33792   32  228    0.35746    0.21507  39.8%  62.2   50s\n",
      " 35498  6102    0.30312   39  237    0.35746    0.21507  39.8%  62.2   55s\n",
      " 35505  6107    0.24090   46  261    0.35746    0.21507  39.8%  62.1   60s\n",
      " 35513  6112    0.23999   34  256    0.35746    0.21507  39.8%  62.1   65s\n",
      " 35520  6117    0.25308   40  271    0.35746    0.21507  39.8%  62.1   70s\n",
      " 35528  6122    0.28126   39  258    0.35746    0.21507  39.8%  62.1   75s\n",
      " 35535  6127    0.29165   35  256    0.35746    0.21507  39.8%  62.1   80s\n",
      " 36885  6247    0.30445   43   28    0.35746    0.21507  39.8%  64.1   85s\n",
      " 42911  6153    0.21507   44  205    0.35746    0.21507  39.8%  66.0   90s\n",
      " 46406  5877    0.23280   35  131    0.35746    0.21507  39.8%  66.5   95s\n",
      " 49439  5572    0.29435   43   25    0.35746    0.21507  39.8%  67.1  100s\n",
      " 52905  5063    0.29931   46   66    0.35746    0.21507  39.8%  67.3  105s\n",
      " 55329  5034 infeasible   43         0.35746    0.21507  39.8%  67.1  110s\n",
      " 67585  6430    0.30391   43   42    0.35746    0.22539  36.9%  65.7  115s\n",
      " 75026  6849 infeasible   51         0.35746    0.23732  33.6%  65.2  120s\n",
      " 80482  7302    0.26504   48   32    0.35746    0.24115  32.5%  65.0  126s\n",
      " 83175  7428    0.28318   40   51    0.35746    0.24226  32.2%  64.9  132s\n",
      " 85072  7634     cutoff   58         0.35746    0.24290  32.0%  64.7  135s\n",
      " 94886  8223    0.32962   48  101    0.35746    0.24956  30.2%  64.1  140s\n",
      " 105254  8507    0.30860   51   45    0.35746    0.26311  26.4%  63.2  145s\n",
      " 109028  8696    0.27441   51  115    0.35746    0.26555  25.7%  62.9  151s\n",
      " 111782  8704     cutoff   43         0.35746    0.26755  25.2%  62.7  155s\n",
      " 124001  8675 infeasible   50         0.35746    0.27753  22.4%  61.7  160s\n",
      " 131939  8085    0.28674   41   34    0.35746    0.28351  20.7%  61.2  165s\n",
      " 137902  7395     cutoff   53         0.35746    0.28726  19.6%  60.7  170s\n",
      " 148543  6461    0.31308   45   39    0.35746    0.29913  16.3%  59.8  175s\n",
      " 156949  5354 infeasible   46         0.35746    0.30657  14.2%  59.2  180s\n",
      " 164543  4306    0.33262   49   77    0.35746    0.31095  13.0%  59.0  185s\n",
      " 171988  3022 infeasible   43         0.35746    0.31829  11.0%  58.3  190s\n",
      " 178383  1756    0.35629   50   58    0.35746    0.32695  8.54%  57.8  195s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 5\n",
      "  Cover: 4\n",
      "  Implied bound: 1\n",
      "  Clique: 8\n",
      "  MIR: 5\n",
      "  Flow cover: 28\n",
      "  GUB cover: 1\n",
      "  Inf proof: 7\n",
      "  Zero half: 10\n",
      "  BQP: 2\n",
      "\n",
      "Explored 185811 nodes (10613566 simplex iterations) in 197.73 seconds (243.52 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 7: 0.357461 0.357461 0.359461 ... 0.386079\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.574611011950e-01, best bound 3.574611011950e-01, gap 0.0000%\n",
      "Set parameter TimeLimit to value 10\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (armlinux64 - \"Ubuntu 24.04.2 LTS\")\n",
      "\n",
      "CPU model: ARM64\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  10\n",
      "\n",
      "Academic license 2755804 - for non-commercial use only - registered to pa___@mit.edu\n",
      "Optimize a model with 4932 rows, 5169 columns and 33911 nonzeros (Min)\n",
      "Model fingerprint: 0x335fb19f\n",
      "Model has 52 linear objective coefficients\n",
      "Variable types: 166 continuous, 5003 integer (5003 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [4e-03, 1e+01]\n",
      "  Objective range  [1e-03, 3e-02]\n",
      "  Bounds range     [1e+00, 5e+00]\n",
      "  RHS range        [3e-02, 1e+01]\n",
      "\n",
      "MIP start from previous solve produced solution with objective 0.357461 (0.02s)\n",
      "Loaded MIP start from previous solve with objective 0.357461\n",
      "\n",
      "Presolve removed 4821 rows and 5084 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 111 rows, 85 columns, 518 nonzeros\n",
      "Variable types: 85 continuous, 0 integer (0 binary)\n",
      "\n",
      "Root relaxation: cutoff, 52 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0     cutoff    0         0.35746    0.35746  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (52 simplex iterations) in 0.03 seconds (0.01 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 0.357461 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.574611011950e-01, best bound 3.574611011950e-01, gap 0.0000%\n",
      "Set parameter TimeLimit to value 300\n",
      "IORFA            RMSE=1.0787  MAE=0.8354  R2=0.3750  fit_s=198.87  gap=0.0  status=2\n",
      "\n",
      "=== abalone_183 ===\n",
      "LinearRegression RMSE=2.9347  MAE=2.2394  R2=0.3812  fit_s=0.01\n",
      "Ridge(alpha=1.0) RMSE=3.2820  MAE=2.3995  R2=0.2260  fit_s=0.00\n",
      "Lasso(alpha=0.01) RMSE=3.1013  MAE=2.3467  R2=0.3089  fit_s=0.01\n",
      "CART             RMSE=4.4721  MAE=3.5385  R2=-0.4371  fit_s=0.00\n",
      "RandomForest     RMSE=4.1606  MAE=3.2313  R2=-0.2438  fit_s=0.34\n",
      "ExtraTrees       RMSE=4.0855  MAE=3.1990  R2=-0.1994  fit_s=0.33\n",
      "GradientBoosting RMSE=4.3656  MAE=3.3813  R2=-0.3694  fit_s=0.03\n",
      "Training data include 37 instances, 10 features.\n",
      "Set parameter OutputFlag to value 1\n",
      "Set parameter LogToConsole to value 1\n",
      "Set parameter TimeLimit to value 300\n",
      "Set parameter Threads to value 0\n",
      "Set parameter Seed to value 0\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (armlinux64 - \"Ubuntu 24.04.2 LTS\")\n",
      "\n",
      "CPU model: ARM64\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  300\n",
      "\n",
      "Academic license 2755804 - for non-commercial use only - registered to pa___@mit.edu\n",
      "Optimize a model with 4962 rows, 4601 columns and 33251 nonzeros (Min)\n",
      "Model fingerprint: 0x806264dc\n",
      "Model has 52 linear objective coefficients\n",
      "Variable types: 168 continuous, 4433 integer (4433 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-03, 1e+01]\n",
      "  Objective range  [1e-03, 3e-02]\n",
      "  Bounds range     [1e+00, 5e+00]\n",
      "  RHS range        [3e-01, 1e+01]\n",
      "Presolve removed 1007 rows and 445 columns\n",
      "Presolve time: 0.08s\n",
      "Presolved: 3955 rows, 4156 columns, 26151 nonzeros\n",
      "Variable types: 138 continuous, 4018 integer (4018 binary)\n",
      "Found heuristic solution: objective 0.3402346\n",
      "Found heuristic solution: objective 0.3332346\n",
      "\n",
      "Root relaxation: objective 1.692110e-01, 694 iterations, 0.01 seconds (0.02 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    0.16921    0  182    0.33323    0.16921  49.2%     -    0s\n",
      "     0     0    0.16921    0  182    0.33323    0.16921  49.2%     -    0s\n",
      "     0     0    0.16921    0  182    0.33323    0.16921  49.2%     -    0s\n",
      "     0     0    0.16921    0  182    0.33323    0.16921  49.2%     -    0s\n",
      "     0     0    0.16921    0  182    0.33323    0.16921  49.2%     -    0s\n",
      "     0     0    0.16921    0  182    0.33323    0.16921  49.2%     -    0s\n",
      "     0     0    0.16921    0  182    0.33323    0.16921  49.2%     -    0s\n",
      "     0     0    0.16921    0  182    0.33323    0.16921  49.2%     -    0s\n",
      "     0     0    0.16921    0  182    0.33323    0.16921  49.2%     -    0s\n",
      "     0     0    0.16921    0  182    0.33323    0.16921  49.2%     -    0s\n",
      "     0     0    0.16921    0  182    0.33323    0.16921  49.2%     -    0s\n",
      "H    0     0                       0.3297929    0.16921  48.7%     -    0s\n",
      "     0     0    0.17011    0  113    0.32979    0.17011  48.4%     -    0s\n",
      "     0     0    0.17011    0  111    0.32979    0.17011  48.4%     -    0s\n",
      "     0     0    0.17011    0  112    0.32979    0.17011  48.4%     -    0s\n",
      "     0     0    0.17011    0  111    0.32979    0.17011  48.4%     -    0s\n",
      "     0     0    0.17011    0  113    0.32979    0.17011  48.4%     -    0s\n",
      "     0     0    0.17011    0  113    0.32979    0.17011  48.4%     -    0s\n",
      "     0     0    0.17011    0  112    0.32979    0.17011  48.4%     -    0s\n",
      "     0     0    0.17011    0  112    0.32979    0.17011  48.4%     -    0s\n",
      "     0     0    0.17011    0  110    0.32979    0.17011  48.4%     -    0s\n",
      "     0     0    0.17011    0  113    0.32979    0.17011  48.4%     -    0s\n",
      "     0     0    0.17011    0  104    0.32979    0.17011  48.4%     -    0s\n",
      "     0     0    0.17011    0  102    0.32979    0.17011  48.4%     -    0s\n",
      "     0     0    0.17011    0  108    0.32979    0.17011  48.4%     -    0s\n",
      "     0     0    0.17011    0  154    0.32979    0.17011  48.4%     -    0s\n",
      "     0     0    0.17011    0  153    0.32979    0.17011  48.4%     -    0s\n",
      "     0     0    0.17111    0  114    0.32979    0.17111  48.1%     -    0s\n",
      "     0     0    0.17111    0  117    0.32979    0.17111  48.1%     -    0s\n",
      "     0     0    0.17111    0  115    0.32979    0.17111  48.1%     -    0s\n",
      "     0     0    0.17111    0   88    0.32979    0.17111  48.1%     -    0s\n",
      "     0     0    0.17111    0  113    0.32979    0.17111  48.1%     -    0s\n",
      "     0     0    0.17111    0  117    0.32979    0.17111  48.1%     -    0s\n",
      "     0     0    0.17111    0  115    0.32979    0.17111  48.1%     -    0s\n",
      "     0     0    0.17111    0  115    0.32979    0.17111  48.1%     -    0s\n",
      "     0     0    0.17115    0  115    0.32979    0.17115  48.1%     -    0s\n",
      "     0     0    0.17121    0  117    0.32979    0.17121  48.1%     -    0s\n",
      "     0     0    0.17121    0  102    0.32979    0.17121  48.1%     -    0s\n",
      "     0     0    0.17211    0  113    0.32979    0.17211  47.8%     -    1s\n",
      "     0     0    0.17211    0  110    0.32979    0.17211  47.8%     -    1s\n",
      "     0     0    0.17211    0  110    0.32979    0.17211  47.8%     -    1s\n",
      "     0     0    0.17211    0  110    0.32979    0.17211  47.8%     -    1s\n",
      "     0     0    0.17211    0  110    0.32979    0.17211  47.8%     -    1s\n",
      "     0     2    0.17211    0  110    0.32979    0.17211  47.8%     -    1s\n",
      "  3091  1375    0.17426   23  126    0.32979    0.17219  47.8%  39.6    5s\n",
      "  4678  1438 infeasible   29         0.32979    0.17219  47.8%  52.6   10s\n",
      " 12230  2628    0.28885   47   24    0.32979    0.17432  47.1%  55.0   15s\n",
      " 15273  3058    0.30513   35   51    0.32979    0.18184  44.9%  56.4   20s\n",
      " 18179  3612 infeasible   37         0.32979    0.19348  41.3%  53.9   25s\n",
      " 30600  5229     cutoff   50         0.32979    0.21313  35.4%  49.9   30s\n",
      " 37493  5702    0.28082   27  110    0.32979    0.22555  31.6%  47.7   40s\n",
      " 37514  5716    0.29642   39  243    0.32979    0.22555  31.6%  47.7   45s\n",
      " 37526  5724    0.27431   37  251    0.32979    0.22555  31.6%  47.7   50s\n",
      " 37540  5733    0.24027   31  283    0.32979    0.22555  31.6%  47.7   55s\n",
      " 37551  5741    0.31612   34  360    0.32979    0.22555  31.6%  47.7   60s\n",
      " 37800  5791    0.22555   35  160    0.32979    0.22555  31.6%  48.5   65s\n",
      " 39245  5759     cutoff   49         0.32979    0.22555  31.6%  50.2   70s\n",
      " 42949  5516    0.23421   38  101    0.32979    0.22555  31.6%  51.8   75s\n",
      " 46080  4974    0.22555   39  105    0.32979    0.22555  31.6%  52.3   80s\n",
      " 47278  4726    0.25610   42   47    0.32979    0.22555  31.6%  52.2   85s\n",
      " 47817  4609    0.26422   43   45    0.32979    0.22555  31.6%  52.3   90s\n",
      " 49210  4294    0.22555   38   74    0.32979    0.22555  31.6%  52.5   95s\n",
      " 52845  3410    0.29872   43   35    0.32979    0.22555  31.6%  52.3  100s\n",
      " 55175  3094    0.22555   46  170    0.32979    0.22555  31.6%  52.4  106s\n",
      " 59647  3229    0.25409   59   80    0.32979    0.22555  31.6%  52.3  110s\n",
      " 67303  3284    0.24177   37   33    0.32979    0.23977  27.3%  51.6  115s\n",
      " 76053  3068     cutoff   41         0.32979    0.26246  20.4%  49.7  120s\n",
      " 82849  2648     cutoff   53         0.32979    0.27606  16.3%  48.1  125s\n",
      " 86248  2266    0.28797   37   47    0.32979    0.28014  15.1%  47.7  130s\n",
      "\n",
      "Cutting planes:\n",
      "  Learned: 1\n",
      "  Gomory: 4\n",
      "  Cover: 6\n",
      "  Implied bound: 10\n",
      "  Clique: 16\n",
      "  MIR: 3\n",
      "  StrongCG: 2\n",
      "  Flow cover: 76\n",
      "  GUB cover: 9\n",
      "  Zero half: 1\n",
      "  RLT: 1\n",
      "  Relax-and-lift: 3\n",
      "\n",
      "Explored 97644 nodes (4418960 simplex iterations) in 134.11 seconds (172.52 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 3: 0.329793 0.333235 0.340235 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.297928840705e-01, best bound 3.297928840705e-01, gap 0.0000%\n",
      "Set parameter TimeLimit to value 10\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (armlinux64 - \"Ubuntu 24.04.2 LTS\")\n",
      "\n",
      "CPU model: ARM64\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  10\n",
      "\n",
      "Academic license 2755804 - for non-commercial use only - registered to pa___@mit.edu\n",
      "Optimize a model with 4962 rows, 4601 columns and 33251 nonzeros (Min)\n",
      "Model fingerprint: 0xcdc3be4f\n",
      "Model has 52 linear objective coefficients\n",
      "Variable types: 168 continuous, 4433 integer (4433 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-03, 1e+01]\n",
      "  Objective range  [1e-03, 3e-02]\n",
      "  Bounds range     [1e+00, 5e+00]\n",
      "  RHS range        [3e-01, 1e+01]\n",
      "\n",
      "MIP start from previous solve produced solution with objective 0.329793 (0.01s)\n",
      "Loaded MIP start from previous solve with objective 0.329793\n",
      "\n",
      "Presolve removed 4872 rows and 4529 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 90 rows, 72 columns, 420 nonzeros\n",
      "Variable types: 72 continuous, 0 integer (0 binary)\n",
      "\n",
      "Root relaxation: interrupted, 38 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0          -    0         0.32979    0.32979  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (38 simplex iterations) in 0.04 seconds (0.01 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 0.329793 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.297928840705e-01, best bound 3.297923678839e-01, gap 0.0002%\n",
      "Set parameter TimeLimit to value 300\n",
      "IORFA            RMSE=3.3855  MAE=2.3965  R2=0.1764  fit_s=136.03  gap=1.5651840651123021e-06  status=2\n",
      "\n",
      "=== wine_quality_287 ===\n",
      "LinearRegression RMSE=0.8883  MAE=0.6631  R2=0.2831  fit_s=0.00\n",
      "Ridge(alpha=1.0) RMSE=0.9054  MAE=0.6718  R2=0.2551  fit_s=0.00\n",
      "Lasso(alpha=0.01) RMSE=0.9155  MAE=0.6789  R2=0.2384  fit_s=0.00\n",
      "CART             RMSE=1.1435  MAE=0.6923  R2=-0.1882  fit_s=0.00\n",
      "RandomForest     RMSE=1.1228  MAE=0.7590  R2=-0.1454  fit_s=0.31\n",
      "ExtraTrees       RMSE=1.0764  MAE=0.6744  R2=-0.0526  fit_s=0.30\n",
      "GradientBoosting RMSE=1.1590  MAE=0.8380  R2=-0.2205  fit_s=0.04\n",
      "Training data include 37 instances, 11 features.\n",
      "Set parameter OutputFlag to value 1\n",
      "Set parameter LogToConsole to value 1\n",
      "Set parameter TimeLimit to value 300\n",
      "Set parameter Threads to value 0\n",
      "Set parameter Seed to value 0\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (armlinux64 - \"Ubuntu 24.04.2 LTS\")\n",
      "\n",
      "CPU model: ARM64\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  300\n",
      "\n",
      "Academic license 2755804 - for non-commercial use only - registered to pa___@mit.edu\n",
      "Optimize a model with 4977 rows, 5892 columns and 39422 nonzeros (Min)\n",
      "Model fingerprint: 0x1d75b960\n",
      "Model has 52 linear objective coefficients\n",
      "Variable types: 169 continuous, 5723 integer (5723 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [5e-04, 1e+01]\n",
      "  Objective range  [1e-03, 3e-02]\n",
      "  Bounds range     [1e+00, 5e+00]\n",
      "  RHS range        [6e-02, 1e+01]\n",
      "Presolve removed 941 rows and 386 columns\n",
      "Presolve time: 0.12s\n",
      "Presolved: 4036 rows, 5506 columns, 29105 nonzeros\n",
      "Variable types: 153 continuous, 5353 integer (5353 binary)\n",
      "Found heuristic solution: objective 0.6439732\n",
      "Found heuristic solution: objective 0.6369732\n",
      "\n",
      "Root relaxation: objective 3.186183e-01, 760 iterations, 0.02 seconds (0.02 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    0.31862    0  230    0.63697    0.31862  50.0%     -    0s\n",
      "     0     0    0.31862    0  231    0.63697    0.31862  50.0%     -    0s\n",
      "     0     0    0.31862    0  231    0.63697    0.31862  50.0%     -    0s\n",
      "     0     0    0.31862    0  231    0.63697    0.31862  50.0%     -    0s\n",
      "     0     0    0.31862    0  231    0.63697    0.31862  50.0%     -    0s\n",
      "     0     0    0.31862    0  230    0.63697    0.31862  50.0%     -    0s\n",
      "     0     0    0.31862    0  231    0.63697    0.31862  50.0%     -    0s\n",
      "     0     0    0.31862    0  231    0.63697    0.31862  50.0%     -    0s\n",
      "     0     0    0.31862    0  230    0.63697    0.31862  50.0%     -    0s\n",
      "     0     0    0.31862    0  231    0.63697    0.31862  50.0%     -    0s\n",
      "     0     0    0.31862    0  230    0.63697    0.31862  50.0%     -    0s\n",
      "H    0     0                       0.6291407    0.31862  49.4%     -    0s\n",
      "     0     0    0.31949    0  117    0.62914    0.31949  49.2%     -    0s\n",
      "     0     0    0.31949    0  114    0.62914    0.31949  49.2%     -    0s\n",
      "     0     0    0.31949    0  114    0.62914    0.31949  49.2%     -    0s\n",
      "     0     0    0.31949    0  133    0.62914    0.31949  49.2%     -    0s\n",
      "     0     0    0.31949    0  123    0.62914    0.31949  49.2%     -    0s\n",
      "     0     0    0.31949    0  109    0.62914    0.31949  49.2%     -    0s\n",
      "     0     0    0.31949    0  108    0.62914    0.31949  49.2%     -    0s\n",
      "     0     0    0.31949    0  108    0.62914    0.31949  49.2%     -    0s\n",
      "     0     0    0.31949    0  108    0.62914    0.31949  49.2%     -    0s\n",
      "     0     0    0.31949    0  108    0.62914    0.31949  49.2%     -    0s\n",
      "     0     0    0.31949    0  108    0.62914    0.31949  49.2%     -    0s\n",
      "     0     0    0.31949    0  107    0.62914    0.31949  49.2%     -    0s\n",
      "     0     0    0.31949    0  108    0.62914    0.31949  49.2%     -    0s\n",
      "     0     0    0.31949    0  108    0.62914    0.31949  49.2%     -    0s\n",
      "     0     0    0.31962    0   99    0.62914    0.31962  49.2%     -    0s\n",
      "     0     0    0.31962    0   98    0.62914    0.31962  49.2%     -    0s\n",
      "     0     0    0.31962    0   98    0.62914    0.31962  49.2%     -    0s\n",
      "     0     0    0.31962    0   89    0.62914    0.31962  49.2%     -    0s\n",
      "     0     0    0.31962    0   90    0.62914    0.31962  49.2%     -    0s\n",
      "     0     0    0.31962    0   90    0.62914    0.31962  49.2%     -    0s\n",
      "     0     0    0.31962    0   90    0.62914    0.31962  49.2%     -    0s\n",
      "     0     0    0.31962    0   90    0.62914    0.31962  49.2%     -    0s\n",
      "     0     0    0.31962    0   90    0.62914    0.31962  49.2%     -    0s\n",
      "     0     0    0.31962    0   89    0.62914    0.31962  49.2%     -    0s\n",
      "     0     0    0.31962    0   90    0.62914    0.31962  49.2%     -    0s\n",
      "     0     0    0.32049    0  127    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  120    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  120    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  120    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  120    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  120    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  120    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  120    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  119    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  119    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  119    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  108    0.62914    0.32049  49.1%     -    1s\n",
      "     0     0    0.32049    0  103    0.62914    0.32049  49.1%     -    1s\n",
      "     0     0    0.32049    0  102    0.62914    0.32049  49.1%     -    1s\n",
      "     0     0    0.32049    0  102    0.62914    0.32049  49.1%     -    1s\n",
      "     0     0    0.32049    0  103    0.62914    0.32049  49.1%     -    1s\n",
      "     0     0    0.32049    0  103    0.62914    0.32049  49.1%     -    1s\n",
      "     0     0    0.32049    0  102    0.62914    0.32049  49.1%     -    1s\n",
      "     0     0    0.32049    0  103    0.62914    0.32049  49.1%     -    1s\n",
      "     0     0    0.32049    0  103    0.62914    0.32049  49.1%     -    1s\n",
      "     0     0    0.32049    0  103    0.62914    0.32049  49.1%     -    1s\n",
      "     0     0    0.32049    0  103    0.62914    0.32049  49.1%     -    1s\n",
      "     0     0    0.32049    0  127    0.62914    0.32049  49.1%     -    1s\n",
      "     0     0    0.32049    0  127    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  127    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  127    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  127    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  127    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  127    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  127    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  126    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  127    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  127    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  127    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  129    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  126    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  126    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  126    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  126    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  125    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  126    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  125    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  126    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  125    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  126    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  127    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  122    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0   64    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  142    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  143    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  142    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  142    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  142    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  142    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  141    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  142    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  142    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  142    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32049    0  142    0.62914    0.32049  49.1%     -    0s\n",
      "     0     0    0.32060    0  163    0.62914    0.32060  49.0%     -    0s\n",
      "     0     0    0.32060    0  143    0.62914    0.32060  49.0%     -    0s\n",
      "     0     0    0.32060    0  140    0.62914    0.32060  49.0%     -    0s\n",
      "     0     0    0.32060    0   67    0.62914    0.32060  49.0%     -    1s\n",
      "     0     0    0.32062    0  162    0.62914    0.32062  49.0%     -    1s\n",
      "     0     0    0.32062    0  157    0.62914    0.32062  49.0%     -    1s\n",
      "     0     0    0.32062    0  157    0.62914    0.32062  49.0%     -    1s\n",
      "     0     0    0.32062    0  157    0.62914    0.32062  49.0%     -    1s\n",
      "     0     0    0.32062    0  157    0.62914    0.32062  49.0%     -    1s\n",
      "     0     0    0.32062    0  156    0.62914    0.32062  49.0%     -    1s\n",
      "     0     0    0.32062    0  157    0.62914    0.32062  49.0%     -    1s\n",
      "     0     0    0.32062    0  156    0.62914    0.32062  49.0%     -    1s\n",
      "     0     0    0.32062    0  157    0.62914    0.32062  49.0%     -    1s\n",
      "     0     0    0.32062    0  156    0.62914    0.32062  49.0%     -    1s\n",
      "     0     0    0.32062    0  157    0.62914    0.32062  49.0%     -    1s\n",
      "     0     0    0.32149    0  166    0.62914    0.32149  48.9%     -    1s\n",
      "     0     0    0.32149    0  146    0.62914    0.32149  48.9%     -    1s\n",
      "     0     0    0.32149    0   82    0.62914    0.32149  48.9%     -    1s\n",
      "     0     0    0.32149    0  176    0.62914    0.32149  48.9%     -    1s\n",
      "     0     0    0.32149    0  166    0.62914    0.32149  48.9%     -    1s\n",
      "     0     0    0.32149    0  168    0.62914    0.32149  48.9%     -    1s\n",
      "     0     0    0.32149    0  167    0.62914    0.32149  48.9%     -    1s\n",
      "     0     0    0.32149    0  167    0.62914    0.32149  48.9%     -    1s\n",
      "     0     0    0.32149    0  166    0.62914    0.32149  48.9%     -    1s\n",
      "     0     0    0.32149    0  167    0.62914    0.32149  48.9%     -    1s\n",
      "     0     0    0.32149    0  167    0.62914    0.32149  48.9%     -    1s\n",
      "     0     0    0.32149    0  167    0.62914    0.32149  48.9%     -    1s\n",
      "     0     0    0.32149    0  167    0.62914    0.32149  48.9%     -    1s\n",
      "     0     0    0.32149    0  167    0.62914    0.32149  48.9%     -    1s\n",
      "     0     0    0.32149    0  146    0.62914    0.32149  48.9%     -    1s\n",
      "     0     0    0.32149    0  146    0.62914    0.32149  48.9%     -    1s\n",
      "     0     0    0.32149    0  146    0.62914    0.32149  48.9%     -    1s\n",
      "     0     0    0.32149    0  146    0.62914    0.32149  48.9%     -    1s\n",
      "     0     0    0.32149    0  117    0.62914    0.32149  48.9%     -    1s\n",
      "     0     0    0.32149    0  117    0.62914    0.32149  48.9%     -    1s\n",
      "     0     0    0.32149    0  117    0.62914    0.32149  48.9%     -    1s\n",
      "     0     0    0.32149    0  117    0.62914    0.32149  48.9%     -    1s\n",
      "     0     0    0.32149    0  117    0.62914    0.32149  48.9%     -    1s\n",
      "     0     0    0.32149    0  116    0.62914    0.32149  48.9%     -    1s\n",
      "     0     0    0.32149    0  203    0.62914    0.32149  48.9%     -    1s\n",
      "     0     0    0.32149    0  203    0.62914    0.32149  48.9%     -    1s\n",
      "     0     0    0.32149    0  203    0.62914    0.32149  48.9%     -    1s\n",
      "     0     0    0.32149    0  203    0.62914    0.32149  48.9%     -    1s\n",
      "     0     0    0.32149    0  203    0.62914    0.32149  48.9%     -    2s\n",
      "     0     0    0.32149    0  203    0.62914    0.32149  48.9%     -    2s\n",
      "     0     0    0.32149    0  203    0.62914    0.32149  48.9%     -    2s\n",
      "     0     0    0.32149    0  197    0.62914    0.32149  48.9%     -    2s\n",
      "     0     0    0.32149    0  168    0.62914    0.32149  48.9%     -    2s\n",
      "     0     0    0.32149    0  168    0.62914    0.32149  48.9%     -    2s\n",
      "     0     0    0.32149    0  167    0.62914    0.32149  48.9%     -    2s\n",
      "     0     0    0.32149    0  131    0.62914    0.32149  48.9%     -    2s\n",
      "H    0     0                       0.6202450    0.32149  48.2%     -    2s\n",
      "H    0     0                       0.6075829    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  156    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  133    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  116    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  102    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0   97    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0   93    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  117    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  117    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  117    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  117    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  117    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  103    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  114    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  164    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  164    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  164    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  164    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  164    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  164    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  165    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  165    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  164    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  165    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  163    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  163    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  163    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  161    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  163    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  163    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  163    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  161    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  163    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  163    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  163    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  161    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  161    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  185    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  191    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  191    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  185    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  185    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  191    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  189    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  189    0.60758    0.32149  47.1%     -    2s\n",
      "     0     0    0.32149    0  144    0.60758    0.32149  47.1%     -    2s\n",
      "     0     2    0.32149    0  137    0.60758    0.32149  47.1%     -    3s\n",
      "  1802   956 infeasible   29         0.60758    0.32149  47.1%  49.7    5s\n",
      "* 2018   951              37       0.5861907    0.32149  45.2%  51.7    5s\n",
      "H 3163  1345                       0.5705660    0.32149  43.7%  52.4    6s\n",
      "H 3163  1277                       0.5685660    0.32149  43.5%  52.4    6s\n",
      "  4518  1442    0.32149   25  130    0.56857    0.32149  43.5%  59.5   10s\n",
      "  8201  2037    0.39384   39  137    0.56857    0.32154  43.4%  62.6   15s\n",
      " 12516  3612 infeasible   32         0.56857    0.32222  43.3%  64.4   20s\n",
      " 16814  4832    0.38547   38  120    0.56857    0.32290  43.2%  65.2   25s\n",
      " 19731  5422    0.50292   43   81    0.56857    0.32389  43.0%  64.5   31s\n",
      " 28518  6857    0.48711   42   76    0.56857    0.34813  38.8%  63.6   35s\n",
      " 36416  7809    0.48759   45  146    0.56857    0.36526  35.8%  62.3   49s\n",
      " 36418  7810    0.48959   48  184    0.56857    0.36526  35.8%  62.3   50s\n",
      " 36433  7823    0.36526   27  179    0.56857    0.36526  35.8%  62.4   55s\n",
      " 37338  7907    0.42232   39   57    0.56857    0.36526  35.8%  63.6   60s\n",
      " 39494  7848    0.55992   51   41    0.56857    0.36526  35.8%  65.0   65s\n",
      " 39718  7877    0.56651   40   34    0.56857    0.36526  35.8%  65.1   64s\n",
      " 40022  7854    0.36526   40  129    0.56857    0.36526  35.8%  65.2   65s\n",
      " 43192  7745    0.45387   45   81    0.56857    0.36526  35.8%  66.1   70s\n",
      " 46103  7832    0.36526   41  163    0.56857    0.36526  35.8%  66.8   75s\n",
      " 52301  7684    0.36526   69   81    0.56857    0.36526  35.8%  65.9   80s\n",
      " 54225  8553    0.46450   48   84    0.56857    0.36526  35.8%  66.3   88s\n",
      " 57984  7492    0.48679   43   29    0.56857    0.36526  35.8%  64.7   90s\n",
      " 64498  8221    0.45259   45   59    0.56857    0.36526  35.8%  64.6   95s\n",
      " 71915  9916    0.45184   48   53    0.56857    0.36526  35.8%  64.4  101s\n",
      "H79383 11433                       0.5685660    0.36693  35.5%  62.9  104s\n",
      " 79935 11478 infeasible   42         0.56857    0.36932  35.0%  62.9  105s\n",
      " 82749 12185 infeasible   49         0.56857    0.37475  34.1%  62.9  110s\n",
      " 86457 13098    0.52648   55   86    0.56857    0.38030  33.1%  62.7  115s\n",
      " 92519 14192     cutoff   51         0.56857    0.39013  31.4%  62.5  120s\n",
      " 101296 16165    0.41034   49  109    0.56857    0.40748  28.3%  61.8  125s\n",
      " 108676 16795    0.56751   56   90    0.56857    0.41777  26.5%  61.0  132s\n",
      " 110333 16785    0.43633   45   36    0.56857    0.42039  26.1%  60.9  135s\n",
      " 119027 15883    0.47044   53   29    0.56857    0.42477  25.3%  60.4  140s\n",
      "H125443 16406                       0.5685660    0.43343  23.8%  60.1  144s\n",
      " 125799 16463    0.45337   46   86    0.56857    0.43487  23.5%  60.1  145s\n",
      " 126930 16556    0.49158   48   44    0.56857    0.43614  23.3%  60.1  150s\n",
      " 133879 16791    0.44577   52   69    0.56857    0.44454  21.8%  59.9  155s\n",
      " 143393 16910    0.44895   49   51    0.56857    0.44893  21.0%  59.6  160s\n",
      " 146465 17015 infeasible   43         0.56857    0.45127  20.6%  59.5  166s\n",
      " 152725 16608    0.45433   58   36    0.56857    0.45326  20.3%  59.4  170s\n",
      " 161843 16716     cutoff   46         0.56857    0.46565  18.1%  58.8  175s\n",
      " 165073 16677    0.50259   50   52    0.56857    0.46741  17.8%  58.7  182s\n",
      " 166367 16609    0.46872   50   51    0.56857    0.46745  17.8%  58.7  186s\n",
      " 175203 16181    0.53509   55   48    0.56857    0.47662  16.2%  58.4  190s\n",
      " 183965 15697    0.54434   52   21    0.56857    0.48518  14.7%  58.3  195s\n",
      " 191734 14945    0.55698   59   42    0.56857    0.48679  14.4%  58.1  201s\n",
      " 196243 14356    0.48897   54   57    0.56857    0.48773  14.2%  57.9  206s\n",
      " 199013 13972    0.52609   44   31    0.56857    0.48892  14.0%  57.8  210s\n",
      " 207943 13225    0.50464   46   33    0.56857    0.49522  12.9%  57.5  215s\n",
      " 216582 12724    0.50073   53  100    0.56857    0.49972  12.1%  57.4  221s\n",
      " 221422 12741    0.54247   45   37    0.56857    0.50109  11.9%  57.4  225s\n",
      " 227388 12262     cutoff   49         0.56857    0.50312  11.5%  57.4  230s\n",
      " 233677 11270 infeasible   50         0.56857    0.50680  10.9%  57.3  235s\n",
      " 242942 10425 infeasible   47         0.56857    0.52098  8.37%  57.1  240s\n",
      " 251475  9787    0.53127   51   26    0.56857    0.52601  7.48%  57.1  245s\n",
      " 258902  9177    0.52783   57   77    0.56857    0.52761  7.20%  57.2  250s\n",
      " 267741  7541    0.54668   56   57    0.56857    0.52961  6.85%  57.1  255s\n",
      " 273679  6743    0.53954   47  131    0.56857    0.53550  5.82%  57.0  260s\n",
      " 278224  6775 infeasible   51         0.56857    0.54243  4.60%  56.9  266s\n",
      " 285284  6317    0.54563   61   70    0.56857    0.54378  4.36%  56.8  270s\n",
      " 297136  4611    0.56463   65   69    0.56857    0.55256  2.81%  56.3  275s\n",
      " 303554  3703    0.56326   52   30    0.56857    0.56103  1.33%  56.1  280s\n",
      " 308318  3218     cutoff   62         0.56857    0.56218  1.12%  56.0  286s\n",
      " 317098  1482     cutoff   60         0.56857    0.56418  0.77%  55.7  290s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 1\n",
      "  Cover: 9\n",
      "  Implied bound: 5\n",
      "  Clique: 14\n",
      "  MIR: 8\n",
      "  StrongCG: 1\n",
      "  Flow cover: 36\n",
      "  GUB cover: 1\n",
      "  Zero half: 2\n",
      "  RLT: 2\n",
      "  Relax-and-lift: 4\n",
      "  BQP: 1\n",
      "\n",
      "Explored 322313 nodes (17925377 simplex iterations) in 292.04 seconds (373.49 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 8: 0.568566 0.570566 0.586191 ... 0.643973\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 5.685659553398e-01, best bound 5.685659553398e-01, gap 0.0000%\n",
      "Set parameter TimeLimit to value 10\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (armlinux64 - \"Ubuntu 24.04.2 LTS\")\n",
      "\n",
      "CPU model: ARM64\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  10\n",
      "\n",
      "Academic license 2755804 - for non-commercial use only - registered to pa___@mit.edu\n",
      "Optimize a model with 4977 rows, 5892 columns and 39422 nonzeros (Min)\n",
      "Model fingerprint: 0x358f1e09\n",
      "Model has 52 linear objective coefficients\n",
      "Variable types: 169 continuous, 5723 integer (5723 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [5e-04, 1e+01]\n",
      "  Objective range  [1e-03, 3e-02]\n",
      "  Bounds range     [1e+00, 5e+00]\n",
      "  RHS range        [6e-02, 1e+01]\n",
      "\n",
      "MIP start from previous solve produced solution with objective 0.568566 (1.89s)\n",
      "Loaded MIP start from previous solve with objective 0.568566\n",
      "\n",
      "Presolve removed 4866 rows and 5804 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 111 rows, 88 columns, 629 nonzeros\n",
      "Variable types: 88 continuous, 0 integer (0 binary)\n",
      "\n",
      "Root relaxation: cutoff, 53 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0     cutoff    0         0.56857    0.56857  0.00%     -    1s\n",
      "\n",
      "Explored 1 nodes (53 simplex iterations) in 1.92 seconds (0.01 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 0.568566 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 5.685660397009e-01, best bound 5.685660397009e-01, gap 0.0000%\n",
      "Set parameter TimeLimit to value 300\n",
      "IORFA            RMSE=0.9479  MAE=0.6628  R2=0.1836  fit_s=297.20  gap=0.0  status=2\n",
      "\n",
      "=== kin8nm_189 ===\n",
      "LinearRegression RMSE=0.2813  MAE=0.2417  R2=0.0544  fit_s=0.00\n",
      "Ridge(alpha=1.0) RMSE=0.2813  MAE=0.2416  R2=0.0545  fit_s=0.00\n",
      "Lasso(alpha=0.01) RMSE=0.2725  MAE=0.2351  R2=0.1126  fit_s=0.00\n",
      "CART             RMSE=0.2760  MAE=0.2134  R2=0.0896  fit_s=0.00\n",
      "RandomForest     RMSE=0.2525  MAE=0.2171  R2=0.2384  fit_s=0.29\n",
      "ExtraTrees       RMSE=0.2539  MAE=0.2226  R2=0.2296  fit_s=0.43\n",
      "GradientBoosting RMSE=0.2557  MAE=0.2131  R2=0.2186  fit_s=0.04\n",
      "Training data include 37 instances, 8 features.\n",
      "Set parameter OutputFlag to value 1\n",
      "Set parameter LogToConsole to value 1\n",
      "Set parameter TimeLimit to value 300\n",
      "Set parameter Threads to value 0\n",
      "Set parameter Seed to value 0\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (armlinux64 - \"Ubuntu 24.04.2 LTS\")\n",
      "\n",
      "CPU model: ARM64\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  300\n",
      "\n",
      "Academic license 2755804 - for non-commercial use only - registered to pa___@mit.edu\n",
      "Optimize a model with 4932 rows, 5304 columns and 34316 nonzeros (Min)\n",
      "Model fingerprint: 0xa10dae84\n",
      "Model has 52 linear objective coefficients\n",
      "Variable types: 166 continuous, 5138 integer (5138 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-04, 1e+01]\n",
      "  Objective range  [1e-03, 3e-02]\n",
      "  Bounds range     [1e+00, 5e+00]\n",
      "  RHS range        [3e-02, 1e+01]\n",
      "Presolve removed 941 rows and 386 columns\n",
      "Presolve time: 0.12s\n",
      "Presolved: 3991 rows, 4918 columns, 25934 nonzeros\n",
      "Variable types: 150 continuous, 4768 integer (4768 binary)\n",
      "Found heuristic solution: objective 0.7013101\n",
      "\n",
      "Root relaxation: objective 3.507718e-01, 638 iterations, 0.02 seconds (0.02 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    0.35077    0  186    0.70131    0.35077  50.0%     -    0s\n",
      "     0     0    0.35077    0  184    0.70131    0.35077  50.0%     -    0s\n",
      "     0     0    0.35077    0  184    0.70131    0.35077  50.0%     -    0s\n",
      "     0     0    0.35077    0  116    0.70131    0.35077  50.0%     -    0s\n",
      "     0     0    0.35077    0  116    0.70131    0.35077  50.0%     -    0s\n",
      "     0     0    0.35077    0  116    0.70131    0.35077  50.0%     -    0s\n",
      "     0     0    0.35077    0  116    0.70131    0.35077  50.0%     -    0s\n",
      "     0     0    0.35077    0  116    0.70131    0.35077  50.0%     -    0s\n",
      "     0     0    0.35077    0  116    0.70131    0.35077  50.0%     -    0s\n",
      "     0     0    0.35077    0  116    0.70131    0.35077  50.0%     -    0s\n",
      "     0     0    0.35077    0  116    0.70131    0.35077  50.0%     -    0s\n",
      "H    0     0                       0.6947402    0.35077  49.5%     -    0s\n",
      "H    0     0                       0.6514578    0.35077  46.2%     -    0s\n",
      "     0     0    0.35166    0  217    0.65146    0.35166  46.0%     -    1s\n",
      "     0     0    0.35166    0  185    0.65146    0.35166  46.0%     -    1s\n",
      "     0     0    0.35166    0  186    0.65146    0.35166  46.0%     -    1s\n",
      "     0     0    0.35166    0  166    0.65146    0.35166  46.0%     -    1s\n",
      "     0     0    0.35166    0  164    0.65146    0.35166  46.0%     -    1s\n",
      "     0     0    0.35166    0  164    0.65146    0.35166  46.0%     -    1s\n",
      "     0     0    0.35166    0  164    0.65146    0.35166  46.0%     -    1s\n",
      "     0     0    0.35166    0  164    0.65146    0.35166  46.0%     -    1s\n",
      "     0     0    0.35166    0  164    0.65146    0.35166  46.0%     -    1s\n",
      "     0     0    0.35166    0  164    0.65146    0.35166  46.0%     -    1s\n",
      "     0     0    0.35166    0  164    0.65146    0.35166  46.0%     -    1s\n",
      "     0     0    0.35166    0  166    0.65146    0.35166  46.0%     -    1s\n",
      "     0     0    0.35166    0  166    0.65146    0.35166  46.0%     -    1s\n",
      "     0     0    0.35166    0  166    0.65146    0.35166  46.0%     -    1s\n",
      "     0     0    0.35166    0  166    0.65146    0.35166  46.0%     -    1s\n",
      "     0     0    0.35166    0  166    0.65146    0.35166  46.0%     -    1s\n",
      "     0     0    0.35166    0  166    0.65146    0.35166  46.0%     -    1s\n",
      "     0     0    0.35166    0  166    0.65146    0.35166  46.0%     -    1s\n",
      "     0     0    0.35166    0  166    0.65146    0.35166  46.0%     -    1s\n",
      "     0     0    0.35166    0  166    0.65146    0.35166  46.0%     -    1s\n",
      "     0     0    0.35166    0  166    0.65146    0.35166  46.0%     -    1s\n",
      "     0     0    0.35166    0  166    0.65146    0.35166  46.0%     -    1s\n",
      "     0     0    0.35266    0  126    0.65146    0.35266  45.9%     -    2s\n",
      "     0     0    0.35266    0  119    0.65146    0.35266  45.9%     -    2s\n",
      "     0     0    0.35266    0  119    0.65146    0.35266  45.9%     -    2s\n",
      "     0     0    0.35266    0  102    0.65146    0.35266  45.9%     -    2s\n",
      "     0     0    0.35266    0   91    0.65146    0.35266  45.9%     -    2s\n",
      "     0     0    0.35266    0  115    0.65146    0.35266  45.9%     -    3s\n",
      "     0     0    0.35266    0  122    0.65146    0.35266  45.9%     -    3s\n",
      "     0     0    0.35266    0   80    0.65146    0.35266  45.9%     -    3s\n",
      "     0     0    0.35266    0  118    0.65146    0.35266  45.9%     -    3s\n",
      "     0     0    0.35266    0  115    0.65146    0.35266  45.9%     -    3s\n",
      "     0     0    0.35266    0  205    0.65146    0.35266  45.9%     -    3s\n",
      "     0     0    0.35266    0  182    0.65146    0.35266  45.9%     -    3s\n",
      "     0     0    0.35266    0  182    0.65146    0.35266  45.9%     -    3s\n",
      "     0     0    0.35266    0  182    0.65146    0.35266  45.9%     -    3s\n",
      "     0     0    0.35266    0  182    0.65146    0.35266  45.9%     -    3s\n",
      "     0     0    0.35266    0  182    0.65146    0.35266  45.9%     -    3s\n",
      "     0     0    0.35266    0  159    0.65146    0.35266  45.9%     -    3s\n",
      "     0     0    0.35266    0  205    0.65146    0.35266  45.9%     -    3s\n",
      "     0     0    0.35266    0  182    0.65146    0.35266  45.9%     -    3s\n",
      "     0     0    0.35266    0  159    0.65146    0.35266  45.9%     -    3s\n",
      "     0     0    0.35266    0  205    0.65146    0.35266  45.9%     -    3s\n",
      "     0     0    0.35266    0  205    0.65146    0.35266  45.9%     -    3s\n",
      "H    0     0                       0.6476932    0.35269  45.5%     -    3s\n",
      "     0     0    0.35269    0  153    0.64769    0.35269  45.5%     -    3s\n",
      "     0     0    0.35269    0  181    0.64769    0.35269  45.5%     -    3s\n",
      "     0     0    0.35269    0  163    0.64769    0.35269  45.5%     -    3s\n",
      "     0     0    0.35269    0  163    0.64769    0.35269  45.5%     -    3s\n",
      "     0     0    0.35269    0  163    0.64769    0.35269  45.5%     -    3s\n",
      "     0     0    0.35269    0  163    0.64769    0.35269  45.5%     -    3s\n",
      "     0     0    0.35269    0  163    0.64769    0.35269  45.5%     -    3s\n",
      "     0     0    0.35269    0  163    0.64769    0.35269  45.5%     -    3s\n",
      "     0     0    0.35269    0  163    0.64769    0.35269  45.5%     -    3s\n",
      "     0     0    0.35269    0  164    0.64769    0.35269  45.5%     -    3s\n",
      "     0     0    0.35269    0  164    0.64769    0.35269  45.5%     -    3s\n",
      "     0     0    0.35277    0  151    0.64769    0.35277  45.5%     -    4s\n",
      "     0     0    0.35277    0  151    0.64769    0.35277  45.5%     -    4s\n",
      "     0     0    0.35277    0  151    0.64769    0.35277  45.5%     -    4s\n",
      "     0     0    0.35277    0  151    0.64769    0.35277  45.5%     -    4s\n",
      "     0     0    0.35277    0  149    0.64769    0.35277  45.5%     -    4s\n",
      "     0     0    0.35277    0  149    0.64769    0.35277  45.5%     -    4s\n",
      "     0     0    0.35277    0   95    0.64769    0.35277  45.5%     -    4s\n",
      "     0     0    0.35277    0  229    0.64769    0.35277  45.5%     -    4s\n",
      "     0     0    0.35277    0  229    0.64769    0.35277  45.5%     -    4s\n",
      "     0     0    0.35277    0  229    0.64769    0.35277  45.5%     -    4s\n",
      "     0     0    0.35277    0  229    0.64769    0.35277  45.5%     -    4s\n",
      "     0     0    0.35277    0  185    0.64769    0.35277  45.5%     -    4s\n",
      "     0     0    0.35277    0  226    0.64769    0.35277  45.5%     -    5s\n",
      "     0     0    0.35277    0  187    0.64769    0.35277  45.5%     -    5s\n",
      "     0     0    0.35277    0  227    0.64769    0.35277  45.5%     -    5s\n",
      "     0     0    0.35277    0  188    0.64769    0.35277  45.5%     -    5s\n",
      "     0     0    0.35277    0  188    0.64769    0.35277  45.5%     -    5s\n",
      "     0     0    0.35277    0  188    0.64769    0.35277  45.5%     -    5s\n",
      "H    0     0                       0.6388152    0.35277  44.8%     -    5s\n",
      "H    0     0                       0.6352883    0.35277  44.5%     -    5s\n",
      "     0     0    0.35277    0  121    0.63529    0.35277  44.5%     -    5s\n",
      "H    0     0                       0.6351308    0.35277  44.5%     -    6s\n",
      "H    0     0                       0.5696877    0.35277  38.1%     -    6s\n",
      "     0     0    0.35277    0  115    0.56969    0.35277  38.1%     -    6s\n",
      "     0     0    0.35277    0  200    0.56969    0.35277  38.1%     -    6s\n",
      "     0     0    0.35277    0  176    0.56969    0.35277  38.1%     -    6s\n",
      "     0     0    0.35277    0  176    0.56969    0.35277  38.1%     -    6s\n",
      "     0     0    0.35277    0  176    0.56969    0.35277  38.1%     -    6s\n",
      "     0     0    0.35277    0  176    0.56969    0.35277  38.1%     -    6s\n",
      "     0     0    0.35277    0  200    0.56969    0.35277  38.1%     -    6s\n",
      "     0     0    0.35277    0  176    0.56969    0.35277  38.1%     -    6s\n",
      "     0     0    0.35277    0  198    0.56969    0.35277  38.1%     -    6s\n",
      "     0     0    0.35277    0  174    0.56969    0.35277  38.1%     -    6s\n",
      "     0     0    0.35277    0  174    0.56969    0.35277  38.1%     -    6s\n",
      "     0     0    0.35277    0  148    0.56969    0.35277  38.1%     -    6s\n",
      "     0     0    0.35277    0  176    0.56969    0.35277  38.1%     -    6s\n",
      "     0     0    0.35277    0  174    0.56969    0.35277  38.1%     -    6s\n",
      "     0     0    0.35277    0  174    0.56969    0.35277  38.1%     -    6s\n",
      "     0     0    0.35277    0  174    0.56969    0.35277  38.1%     -    6s\n",
      "     0     0    0.35277    0  174    0.56969    0.35277  38.1%     -    6s\n",
      "     0     0    0.35277    0  175    0.56969    0.35277  38.1%     -    6s\n",
      "     0     0    0.35277    0  175    0.56969    0.35277  38.1%     -    6s\n",
      "     0     0    0.35277    0  175    0.56969    0.35277  38.1%     -    6s\n",
      "     0     0    0.35277    0  175    0.56969    0.35277  38.1%     -    6s\n",
      "     0     0    0.35277    0  175    0.56969    0.35277  38.1%     -    6s\n",
      "     0     0    0.35277    0  175    0.56969    0.35277  38.1%     -    6s\n",
      "     0     0    0.35277    0  165    0.56969    0.35277  38.1%     -    6s\n",
      "     0     0    0.35277    0  167    0.56969    0.35277  38.1%     -    6s\n",
      "     0     0    0.35277    0  174    0.56969    0.35277  38.1%     -    6s\n",
      "     0     0    0.35277    0  174    0.56969    0.35277  38.1%     -    6s\n",
      "     0     0    0.35277    0  123    0.56969    0.35277  38.1%     -    6s\n",
      "     0     2    0.35277    0  123    0.56969    0.35277  38.1%     -    6s\n",
      "  2966  1345    0.44392   24  204    0.56969    0.35302  38.0%  56.0   10s\n",
      "  4049  1463    0.56069   38   37    0.56969    0.35302  38.0%  71.7   15s\n",
      "  6114  1294    0.35373   24  181    0.56969    0.35366  37.9%  81.6   20s\n",
      "  8165  1453    0.39653   29  131    0.56969    0.35389  37.9%  86.4   25s\n",
      "  8907  1692    0.35499   29  104    0.56969    0.35400  37.9%  86.6   30s\n",
      " 11676  2238    0.39528   35   99    0.56969    0.35443  37.8%  89.7   35s\n",
      " 15458  2898    0.35529   29  169    0.56969    0.35485  37.7%  90.6   40s\n",
      " 18149  3404 infeasible   39         0.56969    0.35533  37.6%  90.5   46s\n",
      " 18825  3524    0.56052   43   67    0.56969    0.35568  37.6%  91.1   50s\n",
      " 24758  4388    0.53347   36   64    0.56969    0.39387  30.9%  89.8   55s\n",
      " 31623  5088     cutoff   32         0.56969    0.41691  26.8%  88.9   60s\n",
      " 34327  5431 infeasible   35         0.56969    0.42879  24.7%  88.3   66s\n",
      " 35900  5432    0.50946   37   95    0.56969    0.44139  22.5%  87.9   78s\n",
      " 35908  5437    0.52847   48  212    0.56969    0.44139  22.5%  87.8   80s\n",
      " 35917  5443    0.50937   35  193    0.56969    0.44139  22.5%  87.8   85s\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# benchmark_iorfa_real.py\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable, Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# --- Baselines + utilities ---\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_california_housing, load_diabetes, fetch_openml\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DatasetSpec:\n",
    "    name: str\n",
    "    loader: Callable[[int], Tuple[object, np.ndarray]]  # (seed) -> (X (DataFrame-like), y)\n",
    "\n",
    "\n",
    "def _onehot_dense():\n",
    "    \"\"\"\n",
    "    OneHotEncoder that yields dense output across sklearn versions.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "    except TypeError:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "\n",
    "def make_preprocessor_for_df(X):\n",
    "    \"\"\"\n",
    "    Builds a ColumnTransformer for numeric + categorical columns.\n",
    "    Outputs:\n",
    "      - sparse for baseline pipelines (fine)\n",
    "      - dense for IORFA (we'll set sparse_threshold=0.0 to force dense if possible)\n",
    "    \"\"\"\n",
    "    # Works for pandas DataFrame; if user passes numpy, treat all numeric.\n",
    "    try:\n",
    "        import pandas as pd  # noqa: F401\n",
    "        is_df = hasattr(X, \"dtypes\")\n",
    "    except Exception:\n",
    "        is_df = hasattr(X, \"dtypes\")\n",
    "\n",
    "    if not is_df:\n",
    "        # All numeric\n",
    "        numeric_pipe = Pipeline(\n",
    "            steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    "        )\n",
    "        return ColumnTransformer([(\"num\", numeric_pipe, slice(0, X.shape[1]))], remainder=\"drop\")\n",
    "\n",
    "    num_cols = list(X.select_dtypes(include=[\"number\", \"bool\"]).columns)\n",
    "    cat_cols = [c for c in X.columns if c not in num_cols]\n",
    "\n",
    "    numeric_pipe = Pipeline(\n",
    "        steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    "    )\n",
    "    cat_pipe = Pipeline(\n",
    "        steps=[(\"imputer\", SimpleImputer(strategy=\"most_frequent\")), (\"onehot\", _onehot_dense())]\n",
    "    )\n",
    "\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_pipe, num_cols),\n",
    "            (\"cat\", cat_pipe, cat_cols),\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "        sparse_threshold=0.0,  # try to keep output dense (helps IORFA)\n",
    "    )\n",
    "\n",
    "\n",
    "def subsample(X, y, max_n: Optional[int], seed: int):\n",
    "    if max_n is None:\n",
    "        return X, y\n",
    "    n = len(y)\n",
    "    if n <= max_n:\n",
    "        return X, y\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = rng.choice(n, size=max_n, replace=False)\n",
    "    if hasattr(X, \"iloc\"):\n",
    "        return X.iloc[idx], y[idx]\n",
    "    return X[idx], y[idx]\n",
    "\n",
    "\n",
    "def metrics(y_true, y_pred):\n",
    "    mae = float(mean_absolute_error(y_true, y_pred))\n",
    "    mse = float(mean_squared_error(y_true, y_pred))\n",
    "    rmse = float(np.sqrt(mse))\n",
    "    r2 = float(r2_score(y_true, y_pred))\n",
    "    return {\"MAE\": mae, \"RMSE\": rmse, \"R2\": r2, \"MSE\": mse}\n",
    "\n",
    "\n",
    "\n",
    "def make_datasets() -> List[DatasetSpec]:\n",
    "    def diabetes(seed: int):\n",
    "        d = load_diabetes()\n",
    "        X = d.data\n",
    "        y = d.target\n",
    "        rng = np.random.default_rng(seed)\n",
    "        idx = rng.permutation(len(y))\n",
    "        return X[idx], y[idx]\n",
    "\n",
    "    def california(seed: int):\n",
    "        d = fetch_california_housing()\n",
    "        X = d.data\n",
    "        y = d.target\n",
    "        rng = np.random.default_rng(seed)\n",
    "        idx = rng.permutation(len(y))\n",
    "        return X[idx], y[idx]\n",
    "\n",
    "    def openml_regression(data_id: int, target_col: Optional[str] = None):\n",
    "        def _loader(seed: int):\n",
    "            bunch = fetch_openml(data_id=data_id, as_frame=True)\n",
    "            X = bunch.data\n",
    "            y = bunch.target\n",
    "            # If multi-target, pick one column\n",
    "            if hasattr(y, \"shape\") and len(getattr(y, \"shape\", ())) == 2 and y.shape[1] > 1:\n",
    "                if target_col is not None and hasattr(y, \"__getitem__\"):\n",
    "                    yv = np.asarray(y[target_col], dtype=float).ravel()\n",
    "                else:\n",
    "                    yv = np.asarray(y.iloc[:, 0], dtype=float).ravel()\n",
    "            else:\n",
    "                yv = np.asarray(y, dtype=float).ravel()\n",
    "\n",
    "            rng = np.random.default_rng(seed)\n",
    "            idx = rng.permutation(len(yv))\n",
    "            return X.iloc[idx], yv[idx]\n",
    "        return _loader\n",
    "\n",
    "    return [\n",
    "        DatasetSpec(\"diabetes_sklearn\", diabetes),\n",
    "        DatasetSpec(\"california_housing_sklearn\", california),\n",
    "\n",
    "        # OpenML real regression datasets (by data_id)\n",
    "        DatasetSpec(\"abalone_183\", openml_regression(183)),\n",
    "        DatasetSpec(\"wine_quality_287\", openml_regression(287)),\n",
    "        DatasetSpec(\"kin8nm_189\", openml_regression(189)),\n",
    "        DatasetSpec(\"cpu_act_197\", openml_regression(197)),\n",
    "        DatasetSpec(\"cpu_small_562\", openml_regression(562)),\n",
    "        DatasetSpec(\"yacht_hydrodynamics_42370\", openml_regression(42370)),\n",
    "\n",
    "        # Energy Efficiency has 2 targets; pick one if present (names vary; fallback is first col)\n",
    "        DatasetSpec(\"energy_efficiency_1472\", openml_regression(1472, target_col=\"Y1\")),\n",
    "\n",
    "        DatasetSpec(\"concrete_strength_44959\", openml_regression(44959)),\n",
    "    ]\n",
    "\n",
    "\n",
    "def make_baselines(seed: int) -> Dict[str, object]:\n",
    "    return {\n",
    "        \"LinearRegression\": LinearRegression(),\n",
    "        \"Ridge(alpha=1.0)\": Ridge(alpha=1.0, random_state=seed),\n",
    "        \"Lasso(alpha=0.01)\": Lasso(alpha=0.01, max_iter=20000, random_state=seed),\n",
    "        \"CART\": DecisionTreeRegressor(random_state=seed),\n",
    "        \"RandomForest\": RandomForestRegressor(n_estimators=300, random_state=seed, n_jobs=-1),\n",
    "        \"ExtraTrees\": ExtraTreesRegressor(n_estimators=400, random_state=seed, n_jobs=-1),\n",
    "        \"GradientBoosting\": GradientBoostingRegressor(random_state=seed),\n",
    "    }\n",
    "\n",
    "\n",
    "def main():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    # ---- knobs ----\n",
    "    seed = 0\n",
    "    test_size = 0.25\n",
    "\n",
    "    # Keep datasets \"not too big\" in practice\n",
    "    max_n_all = 30        # subsample for ALL models (set None to use full)\n",
    "\n",
    "    # IORFA settings (safe-ish defaults)\n",
    "    iorfa_max_depth = 6\n",
    "    iorfa_alpha = 0.01\n",
    "    iorfa_timelimit = 1200    # seconds per dataset\n",
    "    iorfa_output = True\n",
    "\n",
    "    datasets = make_datasets()\n",
    "    baselines = make_baselines(seed)\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for ds in datasets:\n",
    "        print(f\"\\n=== {ds.name} ===\")\n",
    "        try:\n",
    "            X, y = ds.loader(seed)\n",
    "        except Exception as e:\n",
    "            print(f\"SKIP (load failed): {type(e).__name__}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # subsample globally (keeps not too big)\n",
    "        X, y = subsample(X, y, max_n_all, seed)\n",
    "\n",
    "        # split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=seed\n",
    "        )\n",
    "\n",
    "        # preprocessing\n",
    "        pre = make_preprocessor_for_df(X_train)\n",
    "\n",
    "        # ----- baselines -----\n",
    "        for name, model in baselines.items():\n",
    "            pipe = Pipeline([(\"pre\", pre), (\"model\", model)])\n",
    "            t0 = time.perf_counter()\n",
    "            pipe.fit(X_train, y_train)\n",
    "            fit_s = time.perf_counter() - t0\n",
    "            pred = pipe.predict(X_test)\n",
    "            m = metrics(y_test, pred)\n",
    "            rows.append({\n",
    "                \"dataset\": ds.name, \"model\": name,\n",
    "                \"n_train\": len(y_train), \"n_test\": len(y_test),\n",
    "                \"RMSE\": m[\"RMSE\"], \"MAE\": m[\"MAE\"], \"R2\": m[\"R2\"],\n",
    "                \"fit_seconds\": fit_s, \"iorfa_optgap\": None, \"iorfa_status\": None\n",
    "            })\n",
    "            print(f\"{name:16s} MAE={m['MAE']:.4f}  RMSE={m['RMSE']:.4f}  R2={m['R2']:.4f}  fit_s={fit_s:.2f}\")\n",
    "\n",
    "\n",
    "        # ----- IORFA -----\n",
    "        try:\n",
    "            # (no subsampling needed since max_n_all=max_n_iorfa)\n",
    "            Xi_train, yi_train = X_train, y_train\n",
    "            Xi_test,  yi_test  = X_test,  y_test\n",
    "\n",
    "            pre_i = make_preprocessor_for_df(Xi_train)\n",
    "            Xi_train_p = pre_i.fit_transform(Xi_train)\n",
    "            Xi_test_p  = pre_i.transform(Xi_test)\n",
    "\n",
    "            # scale y for IORFA only\n",
    "            y_mu = float(np.mean(yi_train))\n",
    "            y_sd = float(np.std(yi_train)) if float(np.std(yi_train)) > 1e-9 else 1.0\n",
    "            yi_train_s = (yi_train - y_mu) / y_sd\n",
    "\n",
    "            # tighter gamma bounds in scaled space\n",
    "            gamma_bounds = (-5.0, 5.0)\n",
    "\n",
    "            mss = max(2, min(10, int(0.05 * len(yi_train_s))))\n",
    "\n",
    "            model = OptimalRegressionTreeFlow(\n",
    "    max_depth=2,\n",
    "    min_samples_leaf=None,\n",
    "    alpha=1e-3,\n",
    "    routing_formulation=\"bigm\",\n",
    "    leaf_value_formulation=\"bigm\",\n",
    "    max_thresholds=32,            # try 16/32/64\n",
    "    lambda_beta_l1=0,          # sparsify linear term (RuleFit-ish)\n",
    "    lambda_gamma_l1=0.0,          # optional\n",
    "    gamma_bounds=(-5.0, 5.0),  # IMPORTANT\n",
    "    warmstart=False,           # until fixed\n",
    "    polish=True,\n",
    "    polish_timelimit=1.0,\n",
    "    timelimit=600,\n",
    "    output=True,\n",
    ")\n",
    "\n",
    "            t0 = time.perf_counter()\n",
    "            model.fit(Xi_train_p, yi_train_s)\n",
    "            fit_s = time.perf_counter() - t0\n",
    "\n",
    "            pred_s = model.predict(Xi_test_p)\n",
    "            pred   = pred_s * y_sd + y_mu  # unscale back to original y\n",
    "\n",
    "            m = metrics(yi_test, pred)\n",
    "            optgap = getattr(model, \"optgap\", None)\n",
    "            status = getattr(getattr(model, \"m\", None), \"status\", None)\n",
    "\n",
    "            print(f\"{'IORFA':16s} MAE={m['MAE']:.4f}  RMSE={m['RMSE']:.4f}  R2={m['R2']:.4f}  fit_s={fit_s:.2f}  gap={optgap}  status={status}\")\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"IORFA failed: {type(e).__name__}: {e}\")\n",
    "            rows.append({\n",
    "                \"dataset\": ds.name,\n",
    "                \"model\": f\"IORFA(d={iorfa_max_depth},a={iorfa_alpha})\",\n",
    "                \"n_train\": None, \"n_test\": None,\n",
    "                \"RMSE\": None, \"MAE\": None, \"R2\": None,\n",
    "                \"fit_seconds\": None, \"iorfa_optgap\": None, \"iorfa_status\": None,\n",
    "                \"error\": f\"{type(e).__name__}: {e}\",\n",
    "            })\n",
    "\n",
    "    # ----- save results -----\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(\"benchmark_results_real.csv\", index=False)\n",
    "        print(\"\\nSaved: benchmark_results_real.csv\")\n",
    "        print(\"\\nTop rows (sorted by dataset then RMSE):\")\n",
    "        print(df.sort_values([\"dataset\", \"RMSE\"], na_position=\"last\").head(30).to_string(index=False))\n",
    "    except ImportError:\n",
    "        print(\"\\nInstall pandas to save CSV nicely: pip install pandas\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760cc9c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795c5083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c46048d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "an-optimal-rulefit-algorithm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
